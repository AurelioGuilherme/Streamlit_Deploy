import streamlit as st
import torch
import pytorch_lightning as pl
from streamlit_option_menu import option_menu
import numpy as np
import pandas as pd
from functions import helpers


PAGE_TITLE = 'PyTorch Fundamentos ü§ñ'
PAGE_ICON = "ü§ñ"
MENU_LIST =['0 - O que s√£o tensores?',
            '1 - Criando Tensores',
            '2 - Trabalhando com as dimens√µes dos Tensores',
            '3 - Opera√ß√µes aritm√©ticas com Tensores',
            '4 - Concatena√ß√£o, Expans√£o, Jun√ß√£o, Chunk, Squeeze']

st.set_page_config(page_title=PAGE_TITLE,page_icon=PAGE_ICON)
ICON_LIST = []
for i in MENU_LIST:
    ICON_LIST.append('bi bi-droplet')

# Menu lateral
with st.sidebar:
    st.image('imagens/pytorch-logo.png',width=200)
    st.sidebar.title('PyTorch Fundamentos')
    selected = option_menu("",
                           MENU_LIST,
                           icons=ICON_LIST,
                           default_index=0)


st.write("[Conhe√ßa o meu GitHub](https://github.com/AurelioGuilherme)")
st.write("[Documenta√ß√£o PyTorch](https://pytorch.org/docs/stable/index.html)")


def main():
    if selected == '0 - O que s√£o tensores?':
        st.write('# **O que s√£o tensores?**')
        st.write("""
                    O objeto tensor utilizado no framework PyTorch √© focado 
                    e projetado para processamento paralelizado. 
        
                    Ele representa uma estrutura de dados multidimensional 
                    que pode ser manipulada de forma eficiente em GPUs e CPUs. 
        
                    Essa capacidade de processamento paralelo √© essencial 
                    para lidar com grandes conjuntos de dados e realizar 
                    c√°lculos complexos de forma eficiente. 
        
                    Os tensores no PyTorch s√£o a base para a constru√ß√£o de 
                    modelos de aprendizado profundo e outras tarefas de 
                    computa√ß√£o cient√≠fica, fornecendo uma maneira flex√≠vel 
                    e eficaz de representar e manipular dados em v√°rias dimens√µes.
                 """)

        st.image('imagens/tensor.png')

        st.write("""
                    Os tensores s√£o amplamente utilizados em v√°rias √°reas, 
                    incluindo aprendizado de m√°quina, vis√£o computacional, 
                    processamento de linguagem natural e f√≠sica, entre outros. 
        
                    Eles fornecem uma maneira flex√≠vel e eficiente de 
                    representar e manipular dados em v√°rias dimens√µes. 
        
                    No aprendizado de m√°quina, os tensores s√£o usados para 
                    representar conjuntos de dados, par√¢metros de modelo, 
                    gradientes durante o treinamento e resultados de predi√ß√£o. 
        
                    Eles s√£o a base para a constru√ß√£o de modelos de aprendizado 
                    profundo, como redes neurais convolucionais e redes neurais recorrentes. 
        
                    Al√©m disso, em computa√ß√£o cient√≠fica, os tensores s√£o 
                    usados para representar tensores de tens√£o em mec√¢nica, 
                    campos vetoriais em f√≠sica e muito mais. 
                    Sua capacidade de processamento paralelo em hardware 
                    especializado os torna essenciais para lidar com grandes 
                    volumes de dados e realizar c√°lculos complexos de forma eficiente.
                """)
        st.image('imagens/img-1.png')

        st.write("""
                    Os tensores t√™m uma ampla gama de aplica√ß√µes pr√°ticas em diversas √°reas. 
                 
                    No processamento de imagens, os tensores s√£o usados para representar 
                    imagens digitais em tr√™s ou mais dimens√µes (largura, altura e canais de cor). 
        
                    Isso permite realizar opera√ß√µes como convolu√ß√µes e pooling em imagens 
                    para tarefas como classifica√ß√£o e detec√ß√£o de objetos. 
        
                    Em processamento de linguagem natural, os tensores s√£o usados para 
                    representar sequ√™ncias de palavras em texto e realizar opera√ß√µes 
                    como embeddings e aten√ß√£o em modelos de processamento de linguagem. 
        
                    Al√©m disso, em f√≠sica e engenharia, os tensores s√£o usados 
                    para representar grandezas f√≠sicas como tens√£o, deforma√ß√£o e 
                    fluxo de calor em sistemas complexos.
                """)
        st.image('imagens/April-28-deep-learning-applications-infograph.png')
        
    elif selected == '1 - Criando Tensores':
        st.write('# **Criando Tensores**')
        st.write("### Tensores PyTorch x Arrays NumPy:\n")

        st.write("""
                    Os tensores no PyTorch s√£o estruturas de dados multidimensionais 
                    que podem ter uma ou mais dimens√µes. As dimens√µes de um tensor 
                    representam a forma ou o tamanho de cada eixo do tensor. Por exemplo, 
                    um tensor bidimensional tem duas dimens√µes: uma dimens√£o 
                    para linhas e outra para colunas. 
                """)

        st.write('Voc√™ pode criar tensores a partir de listas ou matrizes numpy e vice-versa utilizando a fun√ß√£o `torch.Tensor()`')
        st.write('Esta fun√ß√£o cria um objeto do tipo tensor')
        
        lista_python = [[1,2,3], [4,5,6]]
        t1 = torch.Tensor(lista_python)  
        with st.expander("**Cria um tensor 2x3 a partir de uma lista Python `torch.Tensor()`**"):
            helpers.code_python("""
                                 # Cria um tensor 2x3 a partir de uma lista Python
                                 lista_python = [[1,2,3], [4,5,6]]
                                 t1 = torch.Tensor(lista_python)
                                 print(t1)
                                 print(t1.size())
                                """)
            
            helpers.print_tensor(t1, name='**t1**')
            

        array_numpy = np.array([[9,6,1], [5,3,2]])
        t2 = torch.Tensor(array_numpy)

        # Mostrar c√≥digo
        with st.expander('**Cria um tensor 2x3 a partir de array numpy - `torch.Tensor(array_numpy)`**'):
            helpers.code_python('''
                                 # Cria um tensor 2x3 a partir de um array Numpy                    
                                 array_numpy = np.array([[9,6,1], [5,3,2]])
                                 t2 = torch.Tensor(array_numpy)
                                 print(t2)
                                 print(t2.size())
                                ''')
            helpers.print_tensor(t2,string_custom='**Valor do tensor t2 criado com uma array numpy**')
            

        with st.expander('**Criando um tensor com range de valores - `torch.arange()`**'):
            st.write('√â possivel criar um Tensor com um range de valores com o `torch.arange()`')
            v = torch.arange(5)
            helpers.code_python('''
                                 # Criando tensores com range de valores
                                 v = torch.arange(5)
                                 print(v)
                                 print(v.size())
                                ''')
            helpers.print_tensor(v, string_custom = '**Valor do Tensor v de 1 dimens√£o:**')
            
            st.write('---')

            st.write('''O tensor criado √© em tensor em 1 dimens√£o, 
                        para mudar a dimens√£o podemos utilizar os metodos`torch.reshape()` e o `torch.view()` .''')
            helpers.code_python('''
                                 #Criando tensor em 1 dimens√£o com arange
                                 v = torch.arange(9)
                                 print(v)
                                 print(v.size())
                                ''')
            v = torch.arange(9)
            helpers.print_tensor(v, string_custom = '**Valor tensor v em 1 dimens√£o**')
            
            helpers.code_python('''
                                 # Alterando o tensor para 2 dimens√µes
                                 v = v.view(3,3)
                                 print(v)
                                 print(v.size())
                                ''')
            v = v.view(3,3)
            helpers.print_tensor(v, string_custom = '**Valor do tensor v em 2 dimens√µes**')
            
            
        with st.expander('**Criando um tensor Linear - `torch.linspace()`**'):
            st.write('''
                       O `torch.linspace()` √© particularmente √∫til
                       para gerar tensores lineares com valores igualmente espa√ßados ao 
                       longo de um intervalo especificado.

                        H√° tr√™s argumentos principais: o valor inicial do intervalo,
                        o valor final do intervalo e o n√∫mero de elementos desejados no tensor 
                     ''')
            v = torch.linspace(1, 10, steps=10)
            helpers.code_python(''' 
                                 # Cria um tensor com 10 pontos lineares de (1, 10)
                                 v = torch.linspace(1, 10, steps = 10)
                                 print(v)
                                 print(v.size())
                                ''')
            helpers.print_tensor(v, name = '**v**')
            
            

        with st.expander('**Criando um tensor em escala logar√≠timica - `torch.logspace()`**'):
            st.write('''
                        Ao usar `torch.logspace()`, fornecemos tr√™s argumentos principais: 
                        o expoente inicial, o expoente final e o n√∫mero de elementos desejados no 
                        tensor. O PyTorch ent√£o retorna um tensor com valores distribu√≠dos de forma 
                        logar√≠tmica entre 10^inicio e 10^fim, inclusive.
                    ''')
            v = torch.logspace(start = -1, end = 10, steps = 5 )
            helpers.code_python(''' 
                                 # Criando tensor em escala logar√≠timica    
                                 v = torch.logspace(start = -1, end = 10, steps = 5 )
                                 print(v)
                                 print(v.size())
                                ''')
            helpers.print_tensor(v, string_custom='**Valor do tensor logar√≠timico**')

        with st.expander('**Criando um tensor com valores absolutos - `torch.abs()`**'):
            st.write('''
                       Para criar um tensor com valores absolutos em PyTorch,
                       voc√™ pode usar a fun√ß√£o `torch.abs()` para calcular os valores 
                       absolutos de um tensor existente ou pode criar um tensor com 
                       valores absolutos diretamente.
                     ''')
            f = torch.FloatTensor([-1, -2, 3])
            r = torch.abs(f)
            helpers.code_python('''
                                 # Criando um tensor com valores neg√°tivos    
                                 f = torch.FloatTensor([-1, -2, 3])
                             
                                 # Convertendo o tensor para valores absolutos.
                                 r = torch.abs(f)
                                 print(r)
                                 print(r.size())
                                ''')
            helpers.print_tensor(r,'**Valor do tensor r com valores absolutos**')        

        st.write('### Tipos de Tensores no PyTorch')
        st.write('''
                    Ao criar tensores, podemos especificar suas dimens√µes e 
                    inicializ√°-los com diferentes valores. Por exemplo, 
                    podemos criar um tensor de zeros, onde todos os elementos 
                    do tensor t√™m o valor zero. Isso √© √∫til para inicializar 
                    tensores antes de realizar opera√ß√µes ou preench√™-los com 
                    dados reais posteriormente. Podemos criar um tensor de zeros 
                    usando a fun√ß√£o `torch.zeros(dimens√µes)`, onde "dimens√µes" √© 
                    uma lista ou tupla que especifica o tamanho de cada dimens√£o 
                    do tensor.

                    No entanto, √© importante ter cuidado ao trabalhar com tensores 
                    e gerenciar a mem√≥ria corretamente. √Äs vezes, ao criar ou manipular 
                    tensores, podemos gerar `"lixo de mem√≥ria"`, que s√£o √°reas de mem√≥ria 
                    alocadas para objetos que n√£o est√£o mais em uso, mas ainda n√£o foram liberadas. 
                    Isso pode levar a vazamentos de mem√≥ria e redu√ß√£o do desempenho do programa. 
                    Para evitar o lixo de mem√≥ria, √© importante liberar os recursos adequadamente 
                    ap√≥s o uso, usando m√©todos como "del" em tensores ou utilizando o mecanismo 
                    de coleta de lixo do Python.
                ''')
        a = torch.rand(2,2,3)

        # Mostrar c√≥digo
        with st.expander('**Criando tensor com valores rand√¥micos - `torch.rand()`**'):
            helpers.code_python('''
                                 # Cria um tensor 2 x 2 x 3 com valores rand√¥micos                   
                                 a = torch.rand(2,2,3)
                                 print(a)
                                 print(a.size())
                                ''')
            helpers.print_tensor(a, string_custom='**Tensor com valores rand√¥micos**')
            

        b = torch.zeros(2,2,3)

        # Mostrar c√≥digo
        with st.expander('**Criando um tensor preenchido com zeros - `torch.zeros()`**'):
            helpers.code_python('''
                                 # Criando um tensor preenchido com zeros                  
                                 b = torch.zeros(2,2,3)
                                 print(b)
                                 print(b.size())
                                ''')
            helpers.print_tensor(b, string_custom='**Tensor preenchido com zeros**')

        c = torch.zeros_like(a)
        
        # Mostrar c√≥digo
        with st.expander('**Criando um tensor semelhante a outro - `torch.zeros_like()`**'):
            helpers.code_python('''                                   
                                 # Criando um tensor semelhante a outro              
                                 c = torch.zeros_like(a)
                                 print(c)
                                 print(c.size())
                                ''')
            helpers.print_tensor(c, string_custom='**Tensor com 0 "C" semelhante a "A" (com as mesmas dimens√µes)**')
            

        d = torch.ones_like(a)

        # Mostrar c√≥digo
        with st.expander("**Criando um tensor de 1's semelhante (like) ao tensor de zeros (mesmas dimens√µes) - `torch.ones_like()`**"):
            helpers.code_python('''
                                    # Criando um tensor de 1's semelhante (like) ao tensor de zeros (mesmas dimens√µes)             
                                    d = torch.ones_like(a)
                                    print(d)
                                    print(d.size())
                                ''')
            helpers.print_tensor(d, string_custom='**Tensor com 1 "D" semelhante a "A" (com as mesmas dimens√µes)**')
            
        
        with st.expander('**Tensor Diagonal - `torch.diag()`**'):
             st.write('''Uma das opera√ß√µes comuns em √°lgebra linear √© a cria√ß√£o de uma matriz diagonal, 
                      na qual todos os elementos fora da diagonal principal s√£o zeros e os elementos 
                      na diagonal principal s√£o iguais. Em PyTorch, podemos facilmente criar um tensor 
                      diagonal de uns utilizando a fun√ß√£o `torch.diag()`.''')
             helpers.code_python('''
                                    # Criando tensores de 1's  
                                    v = torch.ones(3)
                                    print(v)
                                    print(v.size())

                                    # Transpondo para um Tensor de Size 3x3
                                    r = torch.diag(v)
                                    print(r)
                                    print(r.size())
                                 ''')
             v = torch.ones(3)
             helpers.print_tensor(v, string_custom="**Tensor de 1's**")

             r = torch.diag(v)
             helpers.print_tensor(r, string_custom='**Tensor "r" diagonal transposto**')

        st.write('### Criando tensores de diferentes tipos')
        st.write("""
                    No PyTorch, existem diferentes tipos de tensores, cada um com suas pr√≥prias caracter√≠sticas e finalidades espec√≠ficas. Os principais tipos de tensores s√£o:

                    1. Tensor Float: Este tipo de tensor √© utilizado para representar n√∫meros reais, sendo frequentemente empregado em tarefas de aprendizado de m√°quina, onde a precis√£o decimal √© importante. Podemos encontrar tensores float de 32 bits (torch.float32 ou torch.float) e 64 bits (torch.float64 ou torch.double), sendo que o primeiro √© mais comumente utilizado devido √† sua efici√™ncia computacional.

                    2. Tensor Inteiro: Este tipo de tensor √© utilizado para representar n√∫meros inteiros. Assim como os tensores float, podemos encontrar tensores inteiros de diferentes tamanhos, como torch.int8, torch.int16, torch.int32 e torch.int64, dependendo da precis√£o necess√°ria para a aplica√ß√£o espec√≠fica.

                    3. Tensor Booleano: Tensores booleanos s√£o utilizados para representar valores l√≥gicos, ou seja, verdadeiro ou falso. Eles s√£o frequentemente utilizados em opera√ß√µes de m√°scara e indexa√ß√£o.

                    4. Tensor Byte: Este tipo de tensor √© semelhante ao tensor booleano, mas pode armazenar valores inteiros de 0 a 255, ocupando menos espa√ßo de mem√≥ria do que um tensor inteiro de 32 bits. √â comumente utilizado em opera√ß√µes de processamento de imagens.

                    A exist√™ncia de m√∫ltiplos tipos de tensores no PyTorch se deve √† necessidade de flexibilidade e efici√™ncia em diferentes cen√°rios de aplica√ß√£o. Cada tipo de tensor oferece um compromisso entre precis√£o e efici√™ncia computacional, permitindo aos desenvolvedores escolher o tipo mais adequado para a sua aplica√ß√£o espec√≠fica. Isso permite otimizar o desempenho e o consumo de recursos do modelo, garantindo ao mesmo tempo a precis√£o necess√°ria para as tarefas em quest√£o.

                    **Vejamos um exemplo de cria√ß√£o tensores:**
                 """)

        a = np.array([[4,5,6], [7,8,9]])
        with st.expander('**Criando numpy array**'):
            helpers.code_python('''
                                 # Array numpy           
                                 a = np.array([[4,5,6], [7,8,9]])
                                 print(f'Tipo de dado Array Numpy: {a.dtype}')
                                ''')
            st.write(f'Tipo de dado Array Numpy: {a.dtype}')
            st.write(a)

        st.write('Por padr√£o o PyTorch utiliza o `FloatTensor` ao criar um objeto da classe tensor.')
        st.write('### Ponto de aten√ß√£o:')
        st.write('**CUIDADO:** Um objeto Tensor n√£o inicializado cont√©m dados de lixo de mem√≥ria!')
        
        b = torch.Tensor(a)
        with st.expander('**Criando tensor utilizando o array**'):
            helpers.code_python('''
                                 # Criando um Tensor.       
                                 b = torch.Tensor(a)
                                 print(f'Tipo de dado `Tensor`: {b.type()}')
                                ''')
            st.write(f"Tipo de dado Tensor: {b.type()}", unsafe_allow_html=True)
            st.write(b)
        
        c = torch.FloatTensor(a)
        with st.expander('**Criando tensor um `torch.FloatTensor()` utilizando um array.**'):
            st.code('''
                     # Criando um FloatTensor        
                     c = torch.FloatTensor(a)
                     print(f'Tipo de dado `FloatTensor`: {c.type()}')
                    ''')
            st.write(f"Tipo de dado Tensor: {c.type()}", unsafe_allow_html=True)
            st.write(c)

        d = torch.LongTensor(a)
        with st.expander('**Criando tensor um `torch.LongTensor()` utilizando o array.**'):
            st.code('''
                      # Criando um LongTensor        
                      d = torch.LongTensor(a)
                      print(f'Tipo de dado Tensor: {d.type()}')
                    ''')
            st.write(f"Tipo de dado Tensor: {d.type()}", unsafe_allow_html=True)
            st.write(d)            

        e = [True, False,True, True, True, False]
        f = torch.Tensor(e)
        with st.expander('**Criando tensor a partir da lista de booleanos - `torch.Tensor(bool)`**'):
            st.code('''
                     # Criando tensor a partir da lista de booleanos          
                     e = [True, False, True, True, False]
                     f = torch.Tensor(e)
                     print(f)
                     print(f.type())           
                    ''')
            st.write(f)
            st.write(f.type())
        
        g = torch.zeros(10, dtype = torch.bool)
        with st.expander('**Criando tensor com valores booleanos - `torch.zeros(dtype = torch.bool)`**'):
            st.code('''
                      # Criando tensor com valores booleanos         
                      g = torch.zeros(10, dtype = torch.bool)
                      print(g)
                      print(g.type())
                    ''')
            st.write(g)
            st.write(g.type())
        
        st.write('### Alterando o tipo do tensor:')
        st.write("""
                  √â comum a necessidade de converter tensores de um tipo para outro. Isso pode ser 
                  √∫til em v√°rias situa√ß√µes, como quando precisamos garantir a consist√™ncia dos 
                  tipos de dados em opera√ß√µes matem√°ticas ou quando queremos adaptar os tensores 
                  para diferentes opera√ß√µes ou modelos.
          
                  Para converter um tensor para outro tipo, o PyTorch oferece diversos m√©todos. 
                 Por exemplo, podemos utilizar o m√©todo `torch.float()` para converter um tensor para 
                 ponto flutuante, ou `torch.long()` para converter para n√∫meros inteiros. Tamb√©m √© poss√≠vel
                  utilizar m√©todos como `torch.double()`, `torch.half()`, `torch.bool()`, entre outros, dependendo 
                 das necessidades espec√≠ficas da aplica√ß√£o.
          
                  Vejamos um exemplo de convers√£o de tipos de tensores:
                 """)
        a = np.array([[4,5,6], [7,8,9]])
        c = torch.FloatTensor(a)
        valor = c
        c = c.long()
        
        # Mostrar c√≥digo
        with st.expander('**Mostrar c√≥digo**'):
            st.code('''
                      # Alterando o tipo do tensor:
                      a = np.array([[4,5,6], [7,8,9]])
                      c = torch.FloatTensor(a)
                      print(c.type())
                      c = c.long()
                      print(c)
                      print(c.type())                                     
                    ''')
            st.write(valor.type())
            st.write(c)
            st.write(c.type())
            
    elif selected == '2 - Trabalhando com as dimens√µes dos Tensores':
        st.write('# **Trabalhando com as dimens√µes dos Tensores**')
        st.write('O slicing permite extrair partes espec√≠ficas de um tensor, permitindo o acesso aos elementos desejados.')
        st.write('### Size e Shape de Tensores')
        st.write('Visualizando as dimens√µes dos tensores com `shape` e `size()`')
        st.write('`shape`: √© um atributo')
        st.write('`size()`:  √© um m√©todo')
        
        # Cria um tensor com valores rand√¥micos
        torch.manual_seed(777)
        x = torch.randint(0, 10, size = (2, 3, 4))


        with st.expander('**Mostrar c√≥digo**'):
            st.code('''
                      # Cria um tensor com valores rand√¥micos
                      torch.manual_seed(777)
                      x = torch.randint(0, 10, size = (2, 3, 4))                   
                      print(x)  
                      # Shape - Atributo do objeto tensor
                      x.shape  
                      # Size - M√©todo do objeto tensor
                      x.size()                      
                      # N√∫mero total de elementos no Tensor                                   
                      torch.numel(x)  
                      # Alterando o size do tensor (mas sem mudar o tensor original)
                      print(x.view(2, 2, 6))                                   
                    ''')
            st.write(x.numpy())
            st.write(x.shape)
            st.write(x.size())
            st.write(torch.numel(x))


        st.write('### View')
        st.write('Alterando o size do tensor (mas sem mudar o tensor original) com `view()`')
        
        # Mostrar c√≥digo
        with st.expander('**Alterando o size do tensor - `torch.view()`**'):
            st.code('''      
                      # Cria um tensor com valores rand√¥micos
                      torch.manual_seed(777)
                      x = torch.randint(0, 10, size = (2, 3, 4))                   
                      
                      # Alterando o size do tensor (mas sem mudar o tensor original)
                      print(f"Altera de '{x.size()}' para '{x.view(2, 2, 6).size()}'")     
                      print(x.view(2, 2, 6))                                                     
                    ''')
            helpers.print_tensor(x, string_custom='**Tensor X - size 2x3x4**')
            st.write(f"**Altera de '{x.size()}' para '{x.view(2, 2, 6).size()}'**")
            helpers.print_tensor(x.view(2, 2, 6), string_custom='**Tensor X - com reshape 2x2x6**')
            

        st.write('Tamb√©m podemos usar o m√©todo `torch.view()` para criar um tensor')
        t = torch.arange(60).view(3, 4, 5)
        with st.expander('**Criando um tensor com - `torch.view()`**'):
            st.code('''
                      t = torch.arange(60).view(3, 4, 5)
                      print(t)
                      print(t.size())
                      print(torch.numel(t))
                    ''')
            helpers.print_tensor(t, string_custom='**Tensor criado com `torch.view()`**')
            st.write('**Quantidade de elemenos do tensor:**',torch.numel(t))


        
        def create_tensor(dimensions):
            try:
                return torch.randint(low=0, high=11, size=dimensions)
            except ValueError:
                st.error('**Digite dimens√µes v√°lidas para o tensor (n√∫meros inteiros separados por v√≠rgula).**')

        st.write("### Slicing de Tensores")
        st.write('''
                  Para realizar o slicing de um tensor, precisamos especificar os √≠ndices ou
                  intervalos ao longo de cada dimens√£o do tensor. Podemos usar nota√ß√µes de intervalo 
                 para especificar o slicing de forma concisa e intuitiva.''')
        
        st.write('''
                    Sintaxe:

                    `tensor[tensor_position_start:tensor_position_end, 
                     tensor_dimension_start:tensor_dimension_end, 
                     tensor_value_start:tensor_value_end]`

                    Par√¢metros:

                    - tensor_position_start
                    - tensor_position_end
                    - tensor_dimension_start
                    - tensor_dimension_stop
                    - tensor_value_start
                    - tensor_value_stop
                ''')
        st.write('''
                  Vamos exemplificar com um exemplo interativo onde voc√™ pode fornecer as dimens√µes
                  em um imput logo a baixo:
                 
                  Neste exemplo √© criado um tensor com dimens√µes customizadas de acordo com o input 
                  e com seed definida para ter a possibilidade replica√ß√£o.
                
                  Os valores dos tensores s√£o valore inteiros de 0 a 10.
                 ''')
        st.write('### Exemplo com input:')
        torch.manual_seed(222)
        dim_input = st.text_input("**Digite as dimens√µes do tensor separadas por v√≠rgula (ex: 3,4,5):**")

        if dim_input:
            dimensions = [int(dim) for dim in dim_input.split(',') if dim.isdigit()]
            dimensions = [max(0, min(dim, 9999999)) for dim in dimensions]
            x = create_tensor(dimensions)
            st.write(x)
            st.write('**Fazendo slice**')
            st.write(f'O tensor possui: {x.ndim} dimens√µes') 
            slice_input = st.text_input("Digite os valores para o slice do tensor separados por v√≠rgula (limitado √† quantidade de dimens√µes):")
            try:
                if slice_input:
                    slices = [int(s) for s in slice_input.split(',') if s.isdigit()]
                    result = x[tuple(slices)]
                    st.write("Resultado do slicing:", result)
                    with st.expander('Mostrar c√≥digo: '):
                        st.code(f'''
                                # Cria um tensor com valores rand√¥micos
                                torch.manual_seed(222)
                                x = torch.randint(0, 10, size = {dimensions})
                                print(x)

                                # Slicing do tensor:
                                ### ps o print esta exibindo ':' ao inves de virgulas em casos especificos:
                                ### exemplo correto: print(x[0:1, 0:1, :3])
                                print(x[{str(slice_input).replace(',', ':')}])           
                                ''',language='python')
            except IndexError:
                st.error("√çndices de slice inv√°lidos.")

        st.write('### Slicing')
        st.write('''
                  Fatiar um Tensor com slicing baseado em indexa√ß√£o √© √∫til, 
                  mas pode ser impratic√°vel com tensores de muitas dimens√µes.
                  Para fatiar um tensor 4D no PyTorch, voc√™ pode usar o m√©todo 
                  `torch.narrow()`. Este m√©todo permite especificar as dimens√µes 
                  ao longo das quais deseja fatiar o tensor e os √≠ndices inicial e 
                  final de cada dimens√£o.
                 ''')
        
        st.write('**3 Dimens√µes**')
        x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
        with st.expander('**Criando um tensor**'):
             st.code('''
                       # Criando um tensor
                       x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                       print(x)
                       print(x.size())
                     ''')
             helpers.print_tensor(x, string_custom='Tensor "x"')
            
        y = torch.narrow(x, 0, 0, 2)
        with st.expander('**A partir da dimens√£o de √≠ndice 0, retorne as dimens√µes de √≠ndice 0 a 2 - `torch.narrow()`**'):
             st.code('''
                     # Slicing com narrow
                     y = torch.narrow(x, 0, 0, 2)
                     print(y)
                     print(y.size())
                     ''')        
             helpers.print_tensor(y, string_custom='**Slicing do tensor x com narrow**')
 
        st.write('**4 Dimens√µes**')
        torch.manual_seed(333)
        tensor_4d = torch.randn(4,3,5,7)
        with st.expander('**Cria um tensor de 4 dimens√µes**'):
             st.code('''
                      torch.manual_seed(333)
                      tensor_4d = torch.randn(4,3,5,7)
                      
                      #Quantidade de dimens√µes
                      tensor_4d.dim()
                      print(tensor_4d)
                      print(tensor_4d.size())
                     ''')
             
             helpers.print_tensor(tensor_4d, string_custom='**tensor de 4 dimens√µes**', dim=True)

        sliced_tensor_4d = tensor_4d.narrow(2, 0, 2)
        with st.expander('**A partir da dimens√£o de √≠ndice 2, retorne as dimens√µes entre √≠ndices 0 e 2.**'):
             st.code('''
                      sliced_tensor_4d = tensor_4d.narrow(2, 0, 2)
                      sliced_tensor_4d.shape
                      print(sliced_tensor_4d)
                    ''')
             helpers.print_tensor(sliced_tensor_4d, string_custom='**Slicing tensor 4d**', dim = True)
  
        
        st.write('**5 Dimens√µes**')
        torch.manual_seed(222)
        tensor_5d = torch.randn(4, 3, 5, 7, 3)
        with st.expander('**Cria um tensor de 5 dimens√µes**'):
             st.code(''' 
                       tensor_5d = torch.randn(4, 3, 5, 7, 3)
                       print(tensor_5d.dim())
                       print(tensor_d.size())
                       print(tensor_5d)
                     ''')
             helpers.print_tensor(tensor_5d, string_custom='**Tensor 5 dimens√µes:**', dim = True)

        
        sliced_tensor_5d = tensor_5d.narrow(2, 0, 2).narrow(3, 0, 1)
        with st.expander('**A partir da dimens√£o de √≠ndice 2, retorne as dimens√µes entre √≠ndices 0 e 2.**'):
             st.code('''
                      # Fa√ßa isso em todas as posi√ß√µes e coloca√ß√µes.
                      # Depois disso, a partir da dimens√£o de √≠ndice 3, retorne as dimens√µes os √≠ndices 0 e 1 (ou seja, somente √≠ndice 0)
                      sliced_tensor_5d = tensor_5d.narrow(2, 0, 2).narrow(3, 0, 1)    
                      print(sliced_tensor_5d)
                    ''')
             helpers.print_tensor(sliced_tensor_5d, string_custom='**Tensor 5 dimens√µes com slicing:**', dim = True)

    if selected == '3 - Opera√ß√µes aritm√©ticas com Tensores':
        st.write('# **Opera√ß√µes aritm√©ticas com Tensores**')
        st.write('''
                    Opera√ß√µes aritm√©ticas s√£o essenciais para a manipula√ß√£o e transforma√ß√£o de dados, 
                    desempenhando um papel cr√≠tico em todas as etapas do desenvolvimento de modelos.

                    **Soma e Subtra√ß√£o:**
                    As opera√ß√µes de soma e subtra√ß√£o s√£o simples e frequentemente usadas em opera√ß√µes de 
                    ajuste de par√¢metros, atualiza√ß√£o de gradientes e normaliza√ß√£o de dados. Por exemplo, 
                    ao treinar um modelo, essas opera√ß√µes podem ser usadas para calcular a diferen√ßa entre 
                    a sa√≠da prevista e o valor real (erro), que √© essencial para ajustar os pesos do modelo.
                ''')
        # Cria 2 tensores
        x = torch.rand(2, 3) 
        y = torch.rand(2, 3)

        # Opera√ß√£o de soma
        z1 = x + y
        with st.expander('**Opera√ß√£o de soma `x + y`**'):
             st.code('''
                      # Cria 2 tensores
                      x = torch.rand(2, 3) 
                      y = torch.rand(2, 3)
                       
                      # Opera√ß√£o de soma
                      z1 = x + y
                      print(z1)
                    ''')
             st.write('**Valor de x**', x.numpy())
             st.write('**Valor de y**', y.numpy())
             st.write('**Soma x + y**', z1.numpy())


        with st.expander('**Opera√ß√£o de soma com fun√ß√£o `torch.add()`**'):
             z2 = torch.add(x, y)  
             st.code('''
                        # Cria 2 tensores
                        x = torch.rand(2, 3) 
                        y = torch.rand(2, 3)

                        # Opera√ß√£o soma com `.add`
                        z2 = torch.add(x, y)  
                        print(z2)
                    ''')
             st.write('**Valor de x**', x.numpy())
             st.write('**Valor de y**', y.numpy())
             st.write('**Soma x + y**', z2.numpy())
 
        with st.expander('**Somando valores a todos os elementos do tensor com `torch.add()`**'):
             r = torch.add(x, 10)
             st.code('''
                       # Somando o valor 10 aos elementos do objeto Tensor.
                       r = torch.add(x, 10)
                       print(r)
                     ''')
             st.write('**Valor do tensor r ap√≥s soma**', r)
        
        with st.expander('**Subtra√ß√£o com o m√©todo `torch.sub()`**'):
             st.write('''
                        As formas anteriores para a soma como "x + y" tamb√©m funcionam para
                        o caso da subtra√ß√£o "x-y".
                        O m√©todo `.sub()` tamb√©m √© possivel utilizar de forma in-place e com par√¢metro out.
                     ''')
             x = torch.tensor([1, 2, 3])
             y = torch.sub(x, 1)

             st.code('''
                       # Subtraindo valores
                       x = torch.Tensor([1,2,3])
                       y = torch.sub(x, 1)
                     ''')
             st.write('**Resultado da subtra√ß√£o**', y.numpy())

        st.write('### O Par√¢metro "out" em Opera√ß√µes de Tensores no PyTorch')  
        st.write('''
                   No PyTorch, o par√¢metro `out` em opera√ß√µes de tensores 
                   oferece uma maneira flex√≠vel de controlar onde o resultado 
                   da opera√ß√£o ser√° armazenado. Em muitas situa√ß√µes, podemos 
                   querer atribuir o resultado de uma opera√ß√£o a uma vari√°vel 
                   espec√≠fica ou a um local de mem√≥ria predefinido, e o 
                   par√¢metro "out" nos permite fazer isso de forma eficiente.
                 ''')
        
        v1 = torch.Tensor(2, 3)
        torch.add(x, y, out = v1)
        with st.expander('**Aplica√ß√£o do par√™metro `out`**'):        
             st.code('''
                       # Criando um tensor
                       v1 = torch.Tensor(2, 3)
                       print(v1)
                     ''')
             st.write('**Tensor v1**', v1)
 
             st.code('''
                       # Podemos atribuir o resultado da opera√ß√£o a uma vari√°vel. 
                       # Todos os m√©todos de opera√ß√£o possuem um par√¢metro out para armazenar o resultado.
                       torch.add(x, y, out = v1)
                     ''')
             st.write('**Tensor v1 com soma utilizando parametro `out`**', v1)
            

        st.write('### Aplica√ß√µes do par√¢metro Out') 
        st.write('''
                    **Controle de Mem√≥ria:**
                    Ao realizar opera√ß√µes em tensores, especialmente em modelos 
                    de aprendizado profundo com grandes conjuntos de dados, √© 
                    crucial otimizar o uso de mem√≥ria. O par√¢metro "out" permite 
                    controlar explicitamente onde o resultado da opera√ß√£o ser√° 
                    armazenado, evitando aloca√ß√µes de mem√≥ria desnecess√°rias e 
                    reduzindo a sobrecarga do sistema.

                    **Reutiliza√ß√£o de Mem√≥ria:**
                    Uma das vantagens do uso do par√¢metro "out" √© a capacidade de 
                    reutilizar a mem√≥ria alocada para tensores existentes. Em vez de 
                    alocar novos tensores para armazenar o resultado de uma opera√ß√£o, 
                    podemos especificar um tensor existente como destino para o resultado, 
                    economizando recursos de mem√≥ria e melhorando o desempenho geral.

                    **Efici√™ncia de C√≥digo:**
                    Usar o par√¢metro "out" tamb√©m pode resultar em c√≥digo mais limpo 
                    e leg√≠vel, pois evita a necessidade de atribuir o resultado da opera√ß√£o 
                    a uma vari√°vel separada. Isso pode simplificar o fluxo de trabalho de 
                    desenvolvimento e facilitar a manuten√ß√£o do c√≥digo ao longo do tempo.
                ''')
        
        st.write('### Opera√ß√µes In-place')
        st.write(''' 
                    As opera√ß√µes in-place s√£o aquelas que modificam diretamente o 
                    tensor existente, sem criar um novo tensor para armazenar o 
                    resultado. Isso √© feito alterando os valores dos pr√≥prios 
                    elementos do tensor, em vez de alocar mem√≥ria para um novo 
                    tensor. Como resultado, as opera√ß√µes in-place s√£o mais eficientes 
                    em termos de uso de mem√≥ria e tempo de execu√ß√£o.
                 ''')
        st.write('''
                    **Sintaxe e Exemplos:**
                 
                    A sintaxe para realizar uma opera√ß√£o in-place em PyTorch √© adicionar
                    um sublinhado `_` ao final do nome da opera√ß√£o. Por exemplo, a opera√ß√£o
                    de adi√ß√£o in-place √© representada pelo m√©todo `add_()`.
                 ''')
        
        
            
        with st.expander('**Aplica√ß√£o de In-place operation**'):
             st.code('''
                        # In-place operation
                        # Mesmo que: x = x + y
                        x.add_(y)   
                    ''')
             st.write('**Mesmo que: x = x + y**')
             st.write(x.add_(y))

        st.write('### Somando valores pela indexa√ß√£o')
        st.write('Tamb√©m √© possivel efetuar oper√ß√µes pela indexa√ß√£o semelhante ao numpy') 
        x = torch.rand(2, 3)                     
        x[:, 0] = 0
        st.code('''
                    x[:, 1]                          
                    x[:, 0] = 0
                    print(x)
                ''',language='python')
        st.write(x)

        st.write('### Mais opera√ß√µes - Estat√≠stica')
        with st.expander('**Soma cumulativa `torch.cumsum()`**'):
             st.write('''
                         O m√©todo `.cumsum()` √© a fun√ß√£o que calcula a soma cumulativa ao longo de um eixo 
                         espec√≠fico do tensor, adicionando os elementos do tensor sequencialmente. 
                         Isso √© √∫til em uma variedade de cen√°rios, incluindo processamento de sinais, 
                         an√°lise de s√©ries temporais e em algoritmos de otimiza√ß√£o.
                      
                         Ao usar o m√©todo `cumsum()` em um tensor, podemos controlar o eixo ao longo do 
                         qual desejamos calcular a soma cumulativa. Por padr√£o, a soma cumulativa √© 
                         realizada ao longo do primeiro eixo do tensor, mas podemos especificar o 
                         eixo desejado como um par√¢metro.
                     ''')
             x = torch.Tensor([[1,2,3],
                               [4,5,6],
                               [7,8,9]])
             st.code(''' 
                         # Criando um tensor de 2 dimens√µes
                         x = torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])
                         print(x)
                     ''',language='python')
             st.write('**Valor do tensor x**',x)

             
             r = torch.cumsum(x, dim=0)
             st.code(''' 
                         # Soma acumulada por coluna
                         r = torch.cumsum(x, dim = 0)
                         print(r)
                     ''', language='python')
             st.write('**Soma acumulada por coluna**',r)

 
             r = torch.cumsum(x, dim=1)
             st.code(''' 
                         # Soma acumulada por linha
                         r = torch.cumsum(x, dim = 1)
                         print(r)
                     ''', language='python')
             st.write('**Soma acumulada por linha**', r)


        with st.expander('**M√©dia `torch.mean()`**'):
             st.write('''
                        Ao utilizar o m√©todo `torch.mean()` em um tensor, o PyTorch calcula a 
                        m√©dia de todos os elementos do tensor ou ao longo de um eixo especificado. 
                        Se nenhum eixo for especificado, a m√©dia de todos os elementos do 
                        tensor √© calculada. No entanto, se um eixo for fornecido, o c√°lculo da m√©dia 
                        ser√° realizado ao longo desse eixo.
                     ''')
             r = torch.mean(x)
             st.code('''
                        # Cria 1 tensor de 2 dimens√µes
                        x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                     
                        # M√©dia dos valores do Tensor
                        r = torch.mean(x)       
                        print(r)

                    ''',language='python')
             st.write('**M√©dia dos valores do Tensor**',r)

             r = torch.mean(x, 0)
             st.code('''
                        # M√©dia por coluna
                        r = torch.mean(x, 0) 
                        print(r)
                     ''',language='python')
             st.write('**M√©dia dos valores do Tensor por coluna**')
             st.write(r)

             r = torch.mean(x, 1)
             st.code('''
                        # M√©dia por linha
                        r = torch.mean(x, 1) 
                        print(r)
                     ''',language='python')
             st.write('**M√©dia dos valores do Tensor por linha**')
             st.write(r)
        
        with st.expander('**Desvio padr√£o `torch.std()`**'):
             st.write('''
                        O desvio padr√£o √© uma medida estat√≠stica que indica a dispers√£o 
                        dos valores em torno da m√©dia de um conjunto de dados. No PyTorch, 
                        o c√°lculo do desvio padr√£o de tensores √© facilitado pelo m√©todo `.std()`,
                         que retorna o desvio padr√£o dos elementos do tensor.

                        Ao utilizar o m√©todo `.std()` em um tensor em PyTorch, podemos calcular 
                        rapidamente o desvio padr√£o de todos os elementos do tensor ou ao longo 
                        de um eixo espec√≠fico em tensores multidimensionais. Se nenhum eixo for 
                        especificado, o desvio padr√£o ser√° calculado para todos os elementos do tensor.
                     ''')
             st.code('''
                        import torch
                        # Cria 1 tensor de 2 dimens√µes
                        x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                       
                        # Desvio padr√£o do tensor
                        print(x.std())
                     
                        # Desvio padr√£o por linha
                        print(x.std(dim =1))
                    ''',language='python')
             st.write('**Desvio padr√£o do tensor**')
             st.write(x.std())
             st.write('**Desvio padr√£o do tensor por linha**')
             st.write(x.std(dim = 1))

        with st.expander('**Soma dos elementos do tensor `torch.sum()`**'):
            st.write('''
                        Ao usar o m√©todo .sum() em um tensor, podemos controlar o eixo ao 
                        longo do qual desejamos calcular a soma. Por padr√£o, a soma √© realizada 
                        em todos os elementos do tensor, mas podemos especificar o eixo 
                        desejado como um par√¢metro.''')
            st.code('''
                        import torch
                        # Cria 1 tensor de 2 dimens√µes
                        x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                    
                        # Soma total
                        r = torch.sum(x)         
                        print(r)
                    
                        # Soma por coluna
                        r = torch.sum(x, 0)         
                        print(r)
                    
                        # Soma por linha
                        r = torch.sum(x, 1)         
                        print(r)
                    ''',language='python')
            st.write('**Soma total**')
            st.write(torch.sum(x))
            st.write('**Soma por coluna**')
            st.write(torch.sum(x,0))
            st.write('**Soma por linha**')
            st.write(torch.sum(x,1))
        
        st.write('### Distribui√ß√µes Estat√≠sticas')
        st.write('''PyTorch oferece suporte a uma variedade de distribui√ß√µes estat√≠sticas, o que
                  √© √∫til em muitos cen√°rios de aprendizado de m√°quina e processamento de dados. 
                 Essas distribui√ß√µes s√£o amplamente utilizadas em tarefas como amostragem de dados, 
                 gera√ß√£o de n√∫meros aleat√≥rios e modelagem probabil√≠stica.''')
        with st.expander('**Distribui√ß√£o Uniforme: `Tensor.uniform_()`**'):
             st.write('''A distribui√ß√£o uniforme √© uma das distribui√ß√µes estat√≠sticas 
                      mais simples e amplamente usadas. Ela atribui a mesma probabilidade para 
                      todos os valores dentro de um intervalo. Em outras palavras, todos os valores 
                      dentro do intervalo t√™m a mesma chance de serem escolhidos.''')
             st.code('''
                        # Distribui√ß√£o Uniforme Para Matriz com Range (0, 1)
                        tensor = torch.Tensor(2, 2).uniform_(0, 1)
                        print(tensor)
                    ''',language='python')
             st.write('**Tensor com distribui√ß√£o uniforme**',torch.Tensor(2, 2).uniform_(0, 1).numpy())
             

        with st.expander('**Distribui√ß√£o de Bernoulli `torch.bernoulli()`**'):
             st.write('''A distribui√ß√£o de Bernoulli √© uma das distribui√ß√µes de probabilidade mais 
                      simples e fundamentais em estat√≠stica e teoria da probabilidade. Ela modela 
                      experimentos aleat√≥rios com dois resultados poss√≠veis: sucesso (geralmente 
                      denotado como 1) ou fracasso (geralmente denotado como 0). Esses resultados 
                      s√£o frequentemente interpretados como "sim" ou "n√£o", "verdadeiro" ou "falso", 
                      "positivo" ou "negativo".''')
             st.code('''
                        # Definindo a probabilidade de sucesso (0.7 para este exemplo)
                        p = 0.7
                        # Criando uma distribui√ß√£o de Bernoulli com probabilidade de sucesso p
                        bernoulli_distribution = torch.distributions.Bernoulli(probs=torch.tensor(p))
            
                        # Amostrando valores da distribui√ß√£o de Bernoulli
                        samples = bernoulli_distribution.sample((5,))
                     ''',language='python')
             p = 0.7
             bernoulli_distribution = torch.distributions.Bernoulli(probs=torch.tensor(p))
             samples = bernoulli_distribution.sample((5,))

             st.write("**Amostras de Bernoulli:**", samples.numpy())


        st.write('## **Multiplica√ß√£o de Matrizes**')
        st.write('''
                    Vamos explorar tr√™s tipos fundamentais de multiplica√ß√£o de 
                    matrizes em PyTorch: multiplica√ß√£o elemento a elemento (element-wise), 
                    produto escalar (dot product) e produto vetorial (cross product).
               ''')
        st.write('### Multiplica√ß√£o Element-wise em PyTorch:')
        st.write('''
                 A multiplica√ß√£o elemento a elemento em PyTorch √© realizada diretamente 
                 usando o operador de multiplica√ß√£o (*) ou pelo m√©todo `torch.mul()`. Esta opera√ß√£o √© aplicada entre 
                 dois tensores de mesma forma e resulta em um novo tensor com os elementos 
                 multiplicados elemento a elemento. A multiplica√ß√£o elemento a elemento √© √∫til 
                 em muitas aplica√ß√µes, incluindo opera√ß√µes de ativa√ß√£o em redes neurais e opera√ß√µes 
                 ponto a ponto em processamento de sinais.''')
        st.image('imagens/elementwise.jpg')
        
        with st.expander('**Multiplica√ß√£o Element-wise**'):
             x = torch.Tensor([[1,2],[3,4]])
             y = torch.Tensor([[5,2],[4,5]])
             r = torch.mul(x, y)
             st.code('''
                        # Criando os tensores
                        x = torch.Tensor([[1,2],[3,4]])
                        y = torch.Tensor([[5,2],[4,5]])
                     
                        # Multiplicando tensor x * y    
                        r = torch.mul(x, y) 
                        print(r)
                    ''',language='python')
             st.write('**Resultado da multiplica√ß√£o tensor x*y (Element-Wise)**')
             st.write(r)
        st.write('### Multiplica√ß√£o Dot Product')
        st.write('''
                    O produto escalar ou multiplica√ß√£o Dot Product em PyTorch √© realizado usando a fun√ß√£o `torch.dot()`. 
                    Esta fun√ß√£o calcula o produto escalar entre dois tensores unidimensionais 
                    (vetores), multiplicando seus elementos correspondentes e somando-os. 
                    O produto escalar √© comumente usado em c√°lculos de similaridade, proje√ß√µes 
                    e otimiza√ß√£o de modelos de aprendizado de m√°quina.
                ''')
        st.image('imagens/dotproduct.png')
        with st.expander('**Multiplica√ß√£o Dot Product**'):
             t1 = torch.Tensor([4,2])
             t2 = torch.Tensor([3,1])
             r = torch.dot(t1, t2)
             st.code('''
                        # Criando dois tensores
                        t1 = torch.Tensor([4,2])
                        t2 = torch.Tensor([3,1])

                        # Multiplicando os tensores.
                        r = torch.dot(t1, t2)
                        print(r)   

                        ''', language='python')
             st.write('**Produto escalar t1 * t2 (Dot Product)**')
             st.write(r)

        st.write('### Multiplica√ß√£o Cross Product')
        st.write('''A multiplica√ß√£o Cross product √© um produto de uma  multiplica√ß√£o cruzada
                    onde podemos multiplicar matrizes e vetores com dimens√µes diferentes.''')

        with st.expander('**Multiplica√ß√£o de Matriz por Vetor `torch.mv`**'):
             st.write('Nesta opera√ß√£o, multiplicamos uma matriz por um vetor para obter um novo vetor.')
             mat = torch.randn(2, 4)
             vec = torch.randn(4)
             st.code('''
                        # Criando Matriz e Tensor
                        mat = torch.randn(2, 4)
                        vec = torch.randn(4)
                        print(mat)
                        print(vec)
                     
                        #Multiplicando a matriz e vetor
                        r = torch.mv(mat, vec)
                        print(r)
                    ''',language='python')

             st.write('**Matriz**')
             st.write(mat)
             st.write('**Vetor**')
             st.write(vec)

             st.write('**Multiplica√ß√£o entre Matriz e Vetor**')
             r = torch.mv(mat, vec)
             st.write(r)
             st.write('Tamb√©m √© possivel efetuar uma soma ao multiplicarmos uma Matriz x Vetor `torch.addmv()`')
             st.code('''
                        # Multiplica√ß√£o entre Matriz e Vetor e ao resultado somamos outro vetor.
                        V = torch.randn(2)
                        mat = torch.randn(2, 3)
                        vec = torch.randn(3)
                        
                        # Vetor + (Matriz X Vetor)
                        r = torch.addmv(V, mat, vec)
                        print(r)
                        
                    ''',language='python')
             V = torch.randn(2)
             mat = torch.randn(2, 3)
             vec = torch.randn(3)
             r = torch.addmv(V, mat, vec)
             st.write('**Vetor + (Matriz X Vetor)**')
             st.write(r)

        with st.expander('**Multiplica√ß√£o entre matrizes - Cross Product `torch.cross`**'):
             st.write('''Essa fun√ß√£o aceita dois tensores com a mesma 
                      forma e calcula o produto cruzado entre eles, produzindo um novo tensor''')
             st.code('''
                        # # Multiplica√ß√£o entre Matrizes com produto cruzado (cross product)
                        # Matriz X Matriz
                        
                        m1 = torch.rand(3, 5)
                        m2 = torch.rand(3, 5)
                        r = torch.cross(m1, m2)
                     
                        # Resultado Size 3x5
                        print(r)
                        print(r.size())

                    ''',language='python')
             m1 = torch.rand(3, 5)
             m2 = torch.rand(3, 5)
             r = torch.cross(m1, m2)
             st.write('**Tensor 1**')   
             st.write(m1)
             st.write('**Tensor 2**') 
             st.write(m2)
             st.write('**Resultado Multiplica√ß√£o Cross Product**')
             st.write(r)

    if selected == '4 - Concatena√ß√£o, Expans√£o, Jun√ß√£o, Chunk, Squeeze':
         st.write('# Manipula√ß√£o de Tensores.')
         st.write('Existem diversas formas de manipular e tensores:')
         with st.expander('**Expans√£o: `torch.expand()`**'):
              st.write('''A expans√£o, tamb√©m conhecida como broadcasting, √© uma opera√ß√£o fundamental
                        em PyTorch que permite realizar opera√ß√µes entre tensores de diferentes formas, 
                       ajustando automaticamente as dimens√µes dos tensores menores para que sejam 
                       compat√≠veis com as dimens√µes dos tensores maiores. Essa opera√ß√£o √© especialmente 
                       √∫til quando precisamos realizar opera√ß√µes entre tensores de formas diferentes sem 
                       precisar criar c√≥pias adicionais dos dados.''')
              
              x = torch.tensor([[1],[2],[3]])
              st.code(''' 
                        # Criando um tensor - size 3x1
                        x = torch.tensor([[1],[2],[3]])
                        print(x)
                      ''',language='python')
              st.write('**Tensor - Size 3x1**')
              st.write(x.numpy())

              st.code('''
                      # Expandindo um tensor
                      x.expand(3, 4)
                      ''',language='python')
              st.write(x.expand(3, 4).numpy())

         with st.expander('**Concatena√ß√£o: `torch.cat()`**'):
              st.write(''' A concatena√ß√£o √© uma opera√ß√£o que permite combinar tensores
                        ao longo de um eixo espec√≠fico. Isso √© √∫til para combinar 
                       dados de diferentes fontes ou para aumentar o tamanho de um tensor''')
              st.code('''
                        # Criando tensor - Size 5x3
                        x = torch.randn(5, 3).type(torch.FloatTensor)
                        print(x)
                        ''',language='python')
              x = torch.randn(5, 3).type(torch.FloatTensor)
              st.write('**Tensor x - Size 5x3**')
              st.write(x.numpy())
              
              st.code('''
                        # Concatena√ß√£o por linha
                        x_row = torch.cat((x, x, x), 0)
                        print(x_row)  
                      ''',language='python')
              st.write('**Concatena√ß√£o por linha**')  
              st.write(torch.cat((x, x, x), 0).numpy())
              
              st.code('''
                        # Concatena√ß√£o por coluna
                        x_col = torch.cat((x, x, x), 1)
                        print(x_col)  
                      ''',language='python')
              st.write('**Concatena√ß√£o por coluna**')  
              st.write(torch.cat((x, x, x), 1).numpy())

         with st.expander('**Jun√ß√£o (Stacking): `torch.stack()`**'):
              st.write('''A jun√ß√£o √© uma opera√ß√£o que permite empilhar tensores ao longo 
                       de um novo eixo. Isso √© √∫til para combinar m√∫ltiplos tensores em 
                       um √∫nico tensor multidimensional. ''')
              st.code('''
                        # Criando um tensor com 9 elementos - 1 Dimens√£o
                        v = torch.arange(9)
                        
                        # Alterando as dimens√µes do tensor para 3x3
                        v = v.view(3, 3)
                        print(v)
                    ''',language='python')
              v = torch.arange(9)
              st.write('**Tensor 3x3 - range 0 a 8**')
              st.write(v.view(3,3).numpy())
              st.code('''
                        # Stack
                        v2 = torch.stack((v, v, v))
                        print(v2)
                      ''',language='python')
              st.write('**Tensor empilhado "Stack"**')
              st.write(torch.stack((v,v,v)).numpy())
         
         with st.expander('**Chunk ou split: `torch.chunk()`**'):
              st.write('''A opera√ß√£o de chunk divide um tensor em um n√∫mero espec√≠fico de 
                       partes ao longo de um determinado eixo. Isso pode ser √∫til para dividir 
                       grandes conjuntos de dados em lotes menores para processamento em lotes.
                       ''')
              st.code('''
                        # Criando o Tensor
                        tensor = torch.tensor([[1, 2, 3, 4, 5, 6]])
                        print(tensor)
                ''',language='python')
              tensor = torch.tensor([[1, 2, 3, 4, 5, 6]])
              st.write('**Tensor - 1x6**')
              st.write(tensor.numpy())
              st.write('**Tensor splitado - 2 tensores 1x3**')
              st.write(torch.chunk(tensor, chunks=2, dim=1))
         
         with st.expander('**Squeeze e Unsqueeze: `torch.squeeze()` e `torch.unsqueeze()`**'):
              st.write('''Squeeze remove dimens√µes de tamanho 1 de um tensor, enquanto unsqueeze 
                       adiciona dimens√µes de tamanho 1 a um tensor. Essas opera√ß√µes s√£o √∫teis para 
                       ajustar a forma de um tensor para corresponder √†s expectativas de uma 
                       determinada opera√ß√£o.''')
              st.write('### Squeeze')
              st.code('''
                        # Criando o Tensor size 2x1
                        tensor = torch.ones(2,1)

                        ''',language='python')
              st.write('**Tensor size 2x1x2x1**')
              tensor = torch.ones(2,1,2,1)
              st.write(tensor.numpy())
              st.write("Dimens√µes do tensor ap√≥s squeeze:", tensor.numpy().shape)
              st.write('**Tensor ap√≥s squeeze**')
              st.write(torch.squeeze(tensor).numpy())
              st.write('''Neste exemplo, o tensor x possui tr√™s dimens√µes, com a √∫ltima dimens√£o 
                       tendo tamanho 1. Ap√≥s a aplica√ß√£o de squeeze na √∫ltima dimens√£o, essa dimens√£o 
                       de tamanho 1 √© removida, resultando em um tensor de duas dimens√µes.''')
              st.write('**Squeeze pela dimens√£o 1: Size 2x2x1**')
              st.write(torch.squeeze(tensor,1).numpy())
              st.write("Dimens√µes do tensor ap√≥s squeeze:", torch.squeeze(tensor,1).numpy().shape)
              st.write('---')

              st.write('### Unsqueeze')
              st.write('''Neste exemplo, o tensor x possui duas dimens√µes. Ap√≥s a aplica√ß√£o de unsqueeze
                        na posi√ß√£o 0, uma nova dimens√£o de tamanho 1 √© adicionada, resultando em um tensor 
                       tridimensional.''')
              
              st.code('''
                        # Criando um tensor de dimens√µes mais altas (2 dimens√µes)
                        x = torch.tensor([[1, 2], [3, 4]])
                        print(x)
                     ''',language='python')
              x = torch.tensor([[1, 2], [3, 4]])
              y = torch.unsqueeze(x, dim=0)
              st.write('**Tensor original**')
              st.write(x)
              st.write("Dimens√µes do tensor original:", x.shape)
              st.write('**Tensor ap√≥s unsqueeze:**')
              st.write(y)
              st.write("Dimens√µes do tensor ap√≥s unsqueeze:", y.shape)
                        
        
if __name__ == "__main__":
    main()
