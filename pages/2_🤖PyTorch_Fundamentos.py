import streamlit as st
import torch
import pytorch_lightning as pl
from streamlit_option_menu import option_menu
import numpy as np


PAGE_TITLE = 'PyTorch Fundamentos ü§ñ'
PAGE_ICON = "ü§ñ"
st.set_page_config(page_title=PAGE_TITLE,page_icon=PAGE_ICON)

# Menu lateral
with st.sidebar:
    st.image('imagens/pytorch-logo.png',width=200)
    st.sidebar.title('PyTorch Fundamentos')
    selected = option_menu("",['0 - O que s√£o tensores?',
                               '1 - Criando Tensores',
                               '2 - Trabalhando com as dimens√µes dos Tensores',
                               '3 - Opera√ß√µes aritm√©ticas com Tensores'], 
                           menu_icon="", default_index=0)

st.write("[Conhe√ßa o meu GitHub](https://github.com/AurelioGuilherme)")
st.write("[Documenta√ß√£o PyTorch](https://pytorch.org/docs/stable/index.html)")


def main():
    if selected == '0 - O que s√£o tensores?':
        st.write('# **O que s√£o tensores?**')
        st.write("""
        O objeto tensor utilizado no framework PyTorch √© focado e projetado para processamento paralelizado. 
        
        Ele representa uma estrutura de dados multidimensional que pode ser manipulada de forma eficiente em GPUs e CPUs. 
        
        Essa capacidade de processamento paralelo √© essencial para lidar com grandes conjuntos de dados e realizar c√°lculos complexos de forma eficiente. 
        
        Os tensores no PyTorch s√£o a base para a constru√ß√£o de modelos de aprendizado profundo e outras tarefas de computa√ß√£o cient√≠fica, 
        fornecendo uma maneira flex√≠vel e eficaz de representar e manipular dados em v√°rias dimens√µes.
        """)

        st.image('imagens/tensor.png')

        st.write("""
        Os tensores s√£o amplamente utilizados em v√°rias √°reas, incluindo aprendizado de m√°quina, vis√£o computacional, processamento de linguagem natural e f√≠sica, entre outros. 
        
        Eles fornecem uma maneira flex√≠vel e eficiente de representar e manipular dados em v√°rias dimens√µes. 
        
        No aprendizado de m√°quina, os tensores s√£o usados para representar conjuntos de dados, par√¢metros de modelo, gradientes durante o treinamento e resultados de predi√ß√£o. 
        
        Eles s√£o a base para a constru√ß√£o de modelos de aprendizado profundo, como redes neurais convolucionais e redes neurais recorrentes. 
        
        Al√©m disso, em computa√ß√£o cient√≠fica, os tensores s√£o usados para representar tensores de tens√£o em mec√¢nica, campos vetoriais em f√≠sica e muito mais. 
        Sua capacidade de processamento paralelo em hardware especializado os torna essenciais para lidar com grandes volumes de dados e realizar c√°lculos complexos de forma eficiente.
        """)
        st.image('imagens/img-1.png')

        st.write("""
        Os tensores t√™m uma ampla gama de aplica√ß√µes pr√°ticas em diversas √°reas. 
                 
        No processamento de imagens, os tensores s√£o usados para representar imagens digitais em tr√™s ou mais dimens√µes (largura, altura e canais de cor). 
        
        Isso permite realizar opera√ß√µes como convolu√ß√µes e pooling em imagens para tarefas como classifica√ß√£o e detec√ß√£o de objetos. 
        
        Em processamento de linguagem natural, os tensores s√£o usados para representar sequ√™ncias de palavras em texto e realizar opera√ß√µes como embeddings e aten√ß√£o em modelos de processamento de linguagem. 
        
        Al√©m disso, em f√≠sica e engenharia, os tensores s√£o usados para representar grandezas f√≠sicas como tens√£o, deforma√ß√£o e fluxo de calor em sistemas complexos.
        """)
        st.image('imagens/April-28-deep-learning-applications-infograph.png')
        
    elif selected == '1 - Criando Tensores':
        st.write('# **Criando Tensores**')
        st.write("### Tensores PyTorch x Arrays NumPy:\n")

        st.write("""
        Os tensores no PyTorch s√£o estruturas de dados multidimensionais que podem ter uma ou mais dimens√µes. As dimens√µes de um tensor representam a forma ou o tamanho de cada eixo do tensor. Por exemplo, um tensor bidimensional tem duas dimens√µes: uma dimens√£o para linhas e outra para colunas. 
        """)

        st.write('Voc√™ pode criar tensores a partir de listas ou matrizes numpy e vice-versa utilizando a fun√ß√£o `.Tensor()`')
        st.write('Esta fun√ß√£o cria um objeto do tipo tensor')
        lista_python = [[1,2,3], [4,5,6]]
        t1 = torch.Tensor(lista_python)  

        # Mostrar o c√≥digo
        with st.expander("Cria um tensor 2x3 a partir de uma lista Python"):
            st.code("""
                        import torch

                        # Cria um tensor 2x3 a partir de uma lista Python
                        lista_python = [[1,2,3], [4,5,6]]
                        t1 = torch.Tensor(lista_python)
                        print(t1)
                    """, language="python")
            st.write(t1)

        array_numpy = np.array([[9,6,1], [5,3,2]])
        t2 = torch.Tensor(array_numpy)

        # Mostrar c√≥digo
        with st.expander('Cria um tensor 2x3 a partir de array numpy'):
            st.code('''
                        import torch
                        import numpy as np

                        # Cria um tensor 2x3 a partir de um array Numpy                    
                        array_numpy = np.array([[9,6,1], [5,3,2]])
                        t2 = torch.Tensor(array_numpy)
                        print(t2)                    
                    ''', language='python')
            st.write(t2)

        st.write('### Tipos de Tensores no PyTorch')
        st.write('''
        Ao criar tensores, podemos especificar suas dimens√µes e inicializ√°-los com diferentes valores. Por exemplo, podemos criar um tensor de zeros, onde todos os elementos do tensor t√™m o valor zero. Isso √© √∫til para inicializar tensores antes de realizar opera√ß√µes ou preench√™-los com dados reais posteriormente. Podemos criar um tensor de zeros usando a fun√ß√£o `torch.zeros(dimens√µes)`, onde "dimens√µes" √© uma lista ou tupla que especifica o tamanho de cada dimens√£o do tensor.

        No entanto, √© importante ter cuidado ao trabalhar com tensores e gerenciar a mem√≥ria corretamente. √Äs vezes, ao criar ou manipular tensores, podemos gerar `"lixo de mem√≥ria"`, que s√£o √°reas de mem√≥ria alocadas para objetos que n√£o est√£o mais em uso, mas ainda n√£o foram liberadas. Isso pode levar a vazamentos de mem√≥ria e redu√ß√£o do desempenho do programa. Para evitar o lixo de mem√≥ria, √© importante liberar os recursos adequadamente ap√≥s o uso, usando m√©todos como "del" em tensores ou utilizando o mecanismo de coleta de lixo do Python.
        ''')
        a = torch.rand(2,2,3)

        # Mostrar c√≥digo
        with st.expander('Cria um tensor 2 x 2 x 3 com valores rand√¥micos'):
            st.code('''
                        import torch

                        # Cria um tensor 2 x 2 x 3 com valores rand√¥micos                   
                        a = torch.rand(2,2,3)
                        print(a)                    
                    ''', language='python')
            st.write(a)

        b = torch.zeros(2,2,3)

        # Mostrar c√≥digo
        with st.expander('Criando um tensor preenchido com zeros'):
            st.code('''
                        import torch

                        # Criando um tensor preenchido com zeros                  
                        b = torch.zeros(2,2,3)
                        print(b)                    
                    ''', language='python')
            st.write(b)

        c = torch.zeros_like(a)
        
        # Mostrar c√≥digo
        with st.expander('Criando um tensor semelhante a outro'):
            st.code('''
                        import torch
                                                                 
                        # Criando um tensor semelhante a outro              
                        c = torch.zeros_like(a)
                        print(c)                    
                    ''', language='python')
            st.write(c)

        d = torch.ones_like(a)

        # Mostrar c√≥digo
        with st.expander("Criando um tensor de 1's semelhante (like) ao tensor de zeros (mesmas dimens√µes)"):
            st.code('''
                        import torch

                        # Criando um tensor de 1's semelhante (like) ao tensor de zeros (mesmas dimens√µes)             
                        d = torch.ones_like(a)
                        print(d)                    
                    ''', language='python')
            st.write(d, unsafe_allow_html=True)

        st.write('### Criando tensores de diferentes tipos')
        st.write("""
        No PyTorch, existem diferentes tipos de tensores, cada um com suas pr√≥prias caracter√≠sticas e finalidades espec√≠ficas. Os principais tipos de tensores s√£o:

        1. Tensor Float: Este tipo de tensor √© utilizado para representar n√∫meros reais, sendo frequentemente empregado em tarefas de aprendizado de m√°quina, onde a precis√£o decimal √© importante. Podemos encontrar tensores float de 32 bits (torch.float32 ou torch.float) e 64 bits (torch.float64 ou torch.double), sendo que o primeiro √© mais comumente utilizado devido √† sua efici√™ncia computacional.

        2. Tensor Inteiro: Este tipo de tensor √© utilizado para representar n√∫meros inteiros. Assim como os tensores float, podemos encontrar tensores inteiros de diferentes tamanhos, como torch.int8, torch.int16, torch.int32 e torch.int64, dependendo da precis√£o necess√°ria para a aplica√ß√£o espec√≠fica.

        3. Tensor Booleano: Tensores booleanos s√£o utilizados para representar valores l√≥gicos, ou seja, verdadeiro ou falso. Eles s√£o frequentemente utilizados em opera√ß√µes de m√°scara e indexa√ß√£o.

        4. Tensor Byte: Este tipo de tensor √© semelhante ao tensor booleano, mas pode armazenar valores inteiros de 0 a 255, ocupando menos espa√ßo de mem√≥ria do que um tensor inteiro de 32 bits. √â comumente utilizado em opera√ß√µes de processamento de imagens.

        A exist√™ncia de m√∫ltiplos tipos de tensores no PyTorch se deve √† necessidade de flexibilidade e efici√™ncia em diferentes cen√°rios de aplica√ß√£o. Cada tipo de tensor oferece um compromisso entre precis√£o e efici√™ncia computacional, permitindo aos desenvolvedores escolher o tipo mais adequado para a sua aplica√ß√£o espec√≠fica. Isso permite otimizar o desempenho e o consumo de recursos do modelo, garantindo ao mesmo tempo a precis√£o necess√°ria para as tarefas em quest√£o.
                
        **Vejamos um exemplo de cria√ß√£o tensores:**""")

        a = np.array([[4,5,6], [7,8,9]])
        with st.expander('Criando numpy array'):
            st.code('''
                        import numpy as np

                        # Array numpy           
                        a = np.array([[4,5,6], [7,8,9]])
                        print(f'Tipo de dado Array Numpy: {a.dtype}')
                                       
                    ''', language='python')
            st.write(f'Tipo de dado Array Numpy: {a.dtype}')
            st.write(a)

        st.write('Por padr√£o o PyTorch utiliza o `FloatTensor` ao criar um objeto da classe tensor.')
        st.write('### Ponto de aten√ß√£o:')
        st.write('**CUIDADO:** Um objeto Tensor n√£o inicializado cont√©m dados de lixo de mem√≥ria!')
        
        b = torch.Tensor(a)
        with st.expander('Criando tensor utilizando o array'):
            st.code('''
                        import torch
                    
                        # Criando um Tensor.       
                        b = torch.Tensor(a)
                        print(f'Tipo de dado `Tensor`: {b.type()}')
                                       
                    ''', language='python')
            st.write(f"Tipo de dado Tensor: {b.type()}", unsafe_allow_html=True)
            st.write(b)
        
        c = torch.FloatTensor(a)
        with st.expander('Criando tensor um `FloatTensor` utilizando um array.'):
            st.code('''
                        import torch
                    
                        # Criando um FloatTensor        
                        c = torch.FloatTensor(a)
                        print(f'Tipo de dado `FloatTensor`: {c.type()}')
                                       
                    ''', language='python')
            st.write(f"Tipo de dado Tensor: {c.type()}", unsafe_allow_html=True)
            st.write(c)

        d = torch.LongTensor(a)
        with st.expander('Criando tensor um `LongTensor` utilizando o array.'):
            st.code('''
                        import torch
                    
                        # Criando um LongTensor        
                        d = torch.LongTensor(a)
                        print(f'Tipo de dado Tensor: {d.type()}')
                                       
                    ''', language='python')
            st.write(f"Tipo de dado Tensor: {d.type()}", unsafe_allow_html=True)
            st.write(d)            

        e = [True, False,True, True, True, False]
        f = torch.Tensor(e)
        with st.expander('Criando tensor a partir da lista de booleanos'):
            st.code('''
                        import torch

                        # Criando tensor a partir da lista de booleanos          
                        e = [True, False, True, True, False]
                        f = torch.Tensor(e)
                        print(f)
                        print(f.type())           
                    ''', language='python')
            st.write(f)
            st.write(f.type())
        
        g = torch.zeros(10, dtype = torch.bool)
        with st.expander('Criando tensor com valores booleanos'):
            st.code('''
                        import torch

                        # Criando tensor com valores booleanos         
                        g = torch.zeros(10, dtype = torch.bool)
                        print(g)
                        print(g.type())           
                    ''', language='python')
            st.write(g)
            st.write(g.type())
        
        st.write('### Alterando o tipo do tensor:')
        st.write("""
        √â comum a necessidade de converter tensores de um tipo para outro. Isso pode ser √∫til em v√°rias situa√ß√µes, como quando precisamos garantir a consist√™ncia dos tipos de dados em opera√ß√µes matem√°ticas ou quando queremos adaptar os tensores para diferentes opera√ß√µes ou modelos.

        Para converter um tensor para outro tipo, o PyTorch oferece diversos m√©todos. Por exemplo, podemos utilizar o m√©todo `.float()` para converter um tensor para ponto flutuante, ou `.long()` para converter para n√∫meros inteiros. Tamb√©m √© poss√≠vel utilizar m√©todos como `.double()`, `.half()`, `.bool()`, entre outros, dependendo das necessidades espec√≠ficas da aplica√ß√£o.

        Vejamos um exemplo de convers√£o de tipos de tensores:
                 """)
        a = np.array([[4,5,6], [7,8,9]])
        c = torch.FloatTensor(a)
        valor = c
        c = c.long()
        
        # Mostrar c√≥digo
        with st.expander('Mostrar c√≥digo'):
            st.code('''
                        import torch

                        # Alterando o tipo do tensor:
                        a = np.array([[4,5,6], [7,8,9]])
                        c = torch.FloatTensor(a)
                        print(c.type())
                        c = c.long()
                        print(c)
                        print(c.type())                                     
                    ''', language='python')
            st.write(valor.type())
            st.write(c)
            st.write(c.type())
            
    elif selected == '2 - Trabalhando com as dimens√µes dos Tensores':
        st.write('# **Trabalhando com as dimens√µes dos Tensores**')
        st.write('O slicing permite extrair partes espec√≠ficas de um tensor, permitindo o acesso aos elementos desejados.')
        st.write('### Size e Shape de Tensores')
        st.write('Visualizando as dimens√µes dos tensores com `shape` e `size()`')
        st.write('`shape`: √© um atributo')
        st.write('`size()`:  √© um m√©todo')
        
        # Cria um tensor com valores rand√¥micos
        torch.manual_seed(777)
        x = torch.randint(0, 10, size = (2, 3, 4))


        with st.expander('Mostrar c√≥digo'):
            st.code('''
                        import torch

                        # Cria um tensor com valores rand√¥micos
                        torch.manual_seed(777)
                        x = torch.randint(0, 10, size = (2, 3, 4))                   
                        print(x)

                        # Shape - Atributo do objeto tensor
                        x.shape

                        # Size - M√©todo do objeto tensor
                        x.size()                    

                        # N√∫mero total de elementos no Tensor                                   
                        torch.numel(x)

                        # Alterando o size do tensor (mas sem mudar o tensor original)
                        print(x.view(2, 2, 6))                                   
                    ''', language='python')
            st.write(x)
            st.write(x.shape)
            st.write(x.size())
            st.write(torch.numel(x))


        st.write('### View')
        st.write('Alterando o size do tensor (mas sem mudar o tensor original) com `view()`')
        
        # Mostrar c√≥digo
        with st.expander('Mostrar c√≥digo'):
            st.code('''
import torch
                                         
# Cria um tensor com valores rand√¥micos
torch.manual_seed(777)
x = torch.randint(0, 10, size = (2, 3, 4))                   

# Alterando o size do tensor (mas sem mudar o tensor original)
print(f"Altera de '{x.size()}' para '{x.view(2, 2, 6).size()}'\n")     
print(x.view(2, 2, 6))                                                     
            ''', language='python')
            st.write(f"Altera de '{x.size()}' para '{x.view(2, 2, 6).size()}'\n")
            st.write(x.view(2, 2, 6))

        st.write('Tamb√©m podemos usar o m√©todo `view()` para criar um tensor')
        t = torch.arange(60).view(3, 4, 5)
        with st.expander('Mostrar c√≥digo:'):
            st.code('''
import torch

t = torch.arange(60).view(3, 4, 5)
print(t)
print(t.shape)
print(t.size())
print(torch.numel(t))
''', language= 'python')
            st.write(t) 
            st.write(t.shape) 
            st.write(t.size()) 
            st.write(torch.numel(t))


        
        def create_tensor(dimensions):
            try:
                return torch.randint(low=0, high=11, size=dimensions)
            except ValueError:
                st.error('Digite dimens√µes v√°lidas para o tensor (n√∫meros inteiros separados por v√≠rgula).')

        st.write("### Slicing de Tensores")
        st.write('''
        Para realizar o slicing de um tensor, precisamos especificar os √≠ndices ou intervalos ao longo de cada dimens√£o do tensor. Podemos usar nota√ß√µes de intervalo para especificar o slicing de forma concisa e intuitiva.''')
        
        st.write('''
                    Sintaxe:

                    `tensor[tensor_position_start:tensor_position_end, tensor_dimension_start:tensor_dimension_end , tensor_value_start:tensor_value_end]`

                    Par√¢metros:

                    - tensor_position_start
                    - tensor_position_end
                    - tensor_dimension_start
                    - tensor_dimension_stop
                    - tensor_value_start
                    - tensor_value_stop
                ''')
        st.write('''
                 Vamos exemplificar com um exemplo interativo onde voc√™ pode fornecer as dimens√µes em um imput logo a baixo:
                 
                Neste exemplo √© criado um tensor com dimens√µes customizadas de acordo com o input e com seed definida para ter a possibilidade replica√ß√£o.
                
                Os valores dos tensores s√£o valore inteiros de 0 a 10.
                 ''')
        st.write('### Exemplo com input:')
        torch.manual_seed(222)
        dim_input = st.text_input("Digite as dimens√µes do tensor separadas por v√≠rgula (ex: 3,4,5):")

        if dim_input:
            dimensions = [int(dim) for dim in dim_input.split(',') if dim.isdigit()]
            dimensions = [max(0, min(dim, 9999999)) for dim in dimensions]
            x = create_tensor(dimensions)
            st.write(x)
            st.write('**Fazendo slice**')
            st.write(f'O tensor possui: {x.ndim} dimens√µes') 
            slice_input = st.text_input("Digite os valores para o slice do tensor separados por v√≠rgula (limitado √† quantidade de dimens√µes):")
            try:
                if slice_input:
                    slices = [int(s) for s in slice_input.split(',') if s.isdigit()]
                    result = x[tuple(slices)]  # Convertendo para uma tupla para indexa√ß√£o
                    st.write("Resultado do slicing:", result)
                    with st.expander('Mostrar c√≥digo: '):
                        st.code(f'''
                                # Cria um tensor com valores rand√¥micos
                                torch.manual_seed(222)
                                x = torch.randint(0, 10, size = {dimensions})
                                print(x)

                                # Slicing do tensor:
                                ### ps o print esta exibindo ':' ao inves de virgulas em casos especificos:
                                ### exemplo correto: print(x[0:1, 0:1, :3])
                                print(x[{str(slice_input).replace(',', ':')}])           
                                ''',language='python')
            except IndexError:
                st.error("√çndices de slice inv√°lidos.")

        st.write('''Fatiar um Tensor com slicing baseado em indexa√ß√£o √© √∫til, 
                     mas pode ser impratic√°vel com tensores de muitas dimens√µes.
                     Para fatiar um tensor 4D no PyTorch, voc√™ pode usar o m√©todo 
                     `tensor.narrow()`. Este m√©todo permite especificar as dimens√µes 
                     ao longo das quais deseja fatiar o tensor e os √≠ndices inicial e 
                     final de cada dimens√£o.''')
        
        st.write('**3 Dimens√µes**')
        x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
        with st.expander('Cria um tensor '):
                        st.code(f'''
                                x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                                print(x)
                                ''',language='python')
                        st.write(x)
        y = torch.narrow(x, 0, 0, 2)
        with st.expander('A partir da dimens√£o de √≠ndice 0, retorne as dimens√µes de √≠ndice 0 a 2 '):
                        st.code(f'''
                                y = torch.narrow(x, 0, 0, 2)
                                print(y)
                                ''',language='python')        
                        st.write(y)

        st.write('**4 Dimens√µes**')
        torch.manual_seed(333)
        tensor_4d = torch.randn(4,3,5,7)
        with st.expander('Cria um tensor de 4 dimens√µes'):
             st.code('''
                        torch.manual_seed(333)
                        tensor_4d = torch.randn(4,3,5,7)
                     
                        #Quantidade de dimens√µes
                        tensor_4d.dim()
                        print(tensor_4d)''',language='python')
             st.write(tensor_4d.dim())
             st.write(tensor_4d)
        sliced_tensor_4d = tensor_4d.narrow(2, 0, 2)
        with st.expander('A partir da dimens√£o de √≠ndice 2, retorne as dimens√µes entre √≠ndices 0 e 2. '):
             st.code('''
                        sliced_tensor_4d = tensor_4d.narrow(2, 0, 2)
                        sliced_tensor_4d.shape
                        print(sliced_tensor_4d)
                    ''',language='python')
             st.write(sliced_tensor_4d.shape)
             st.write(sliced_tensor_4d)
        
        st.write('**5 Dimens√µes**')
        torch.manual_seed(222)
        tensor_5d = torch.randn(4, 3, 5, 7, 3)
        with st.expander('Cria um tensor de 5 dimens√µes'):
            st.code(''' 
                        tensor_5d = torch.randn(4, 3, 5, 7, 3)
                        tensor_5d.dim()
                        print(tensor_5d)
                    ''', language='python')
            st.write(tensor_5d.dim())
            st.write(tensor_5d)
        
        sliced_tensor_5d = tensor_5d.narrow(2, 0, 2).narrow(3, 0, 1)
        with st.expander('A partir da dimens√£o de √≠ndice 2, retorne as dimens√µes entre √≠ndices 0 e 2. '):
             st.code('''
                        # Fa√ßa isso em todas as posi√ß√µes e coloca√ß√µes.
                        # Depois disso, a partir da dimens√£o de √≠ndice 3, retorne as dimens√µes os √≠ndices 0 e 1 (ou seja, somente √≠ndice 0)
                        sliced_tensor_5d = tensor_5d.narrow(2, 0, 2).narrow(3, 0, 1)

                        print(sliced_tensor_5d)
                    ''', language='python')
             st.write(sliced_tensor_5d)
    if selected == '3 - Opera√ß√µes aritm√©ticas com Tensores':
        st.write('# **Opera√ß√µes aritm√©ticas com Tensores**', unsafe_allow_html=True)
        st.write('''
                    Opera√ß√µes aritm√©ticas s√£o essenciais para a manipula√ß√£o e transforma√ß√£o de dados, 
                    desempenhando um papel cr√≠tico em todas as etapas do desenvolvimento de modelos.

                    **Soma e Subtra√ß√£o:**
                    As opera√ß√µes de soma e subtra√ß√£o s√£o simples e frequentemente usadas em opera√ß√µes de 
                    ajuste de par√¢metros, atualiza√ß√£o de gradientes e normaliza√ß√£o de dados. Por exemplo, 
                    ao treinar um modelo, essas opera√ß√µes podem ser usadas para calcular a diferen√ßa entre 
                    a sa√≠da prevista e o valor real (erro), que √© essencial para ajustar os pesos do modelo.

                ''')
        # Cria 2 tensores
        x = torch.rand(2, 3) 
        y = torch.rand(2, 3)

        # Opera√ß√£o de soma
        z1 = x + y
        with st.expander('**Opera√ß√£o de soma**'):
             st.code('''
                        # Cria 2 tensores
                        x = torch.rand(2, 3) 
                        y = torch.rand(2, 3)

                        # Opera√ß√£o de soma
                        z1 = x + y
                        print(z1)
                    ''',language='python')
             st.write('**Valor de x**')
             st.write(x)
             st.write('**Valor de y**')
             st.write(y)
             st.write('**Soma x + y**')
             st.write(z1)

        with st.expander('**Opera√ß√£o de soma com fun√ß√£o `.add`**'):
             z2 = torch.add(x, y)  
             st.code('''
                        # Cria 2 tensores
                        x = torch.rand(2, 3) 
                        y = torch.rand(2, 3)

                        # Opera√ß√£o soma com `.add`
                        z2 = torch.add(x, y)  
                        print(z2)
                    ''',language='python')
             st.write('**Valor de x**')
             st.write(x)
             st.write('**Valor de y**')
             st.write(y)
             st.write('**Soma x + y**')
             st.write(z2)
        st.write('### O Par√¢metro "out" em Opera√ß√µes de Tensores no PyTorch')  
        st.write('''
                    No PyTorch, o par√¢metro `out` em opera√ß√µes de tensores 
                    oferece uma maneira flex√≠vel de controlar onde o resultado 
                    da opera√ß√£o ser√° armazenado. Em muitas situa√ß√µes, podemos 
                    querer atribuir o resultado de uma opera√ß√£o a uma vari√°vel 
                    espec√≠fica ou a um local de mem√≥ria predefinido, e o 
                    par√¢metro "out" nos permite fazer isso de forma eficiente.
                 ''')
        v1 = torch.Tensor(2, 3)
        with st.expander('**Aplica√ß√£o do par√™metro `out`**'):        
            
            st.code('''
                        # Criando um tensor
                        v1 = torch.Tensor(2, 3)
                        print(v1)
                    ''',language='python')
            st.write('**Tensor v1**')
            st.write(v1)

            torch.add(x, y, out = v1)
            st.code('''
                        # Podemos atribuir o resultado da opera√ß√£o a uma vari√°vel. 
                        # Todos os m√©todos de opera√ß√£o possuem um par√¢metro out para armazenar o resultado.
                        torch.add(x, y, out = v1)
                    ''',language='python')
            st.write('**Tensor v1 com soma utilizando parametro `out`**')
            st.write(v1)

        st.write('### Aplica√ß√µes do par√¢metro Out') 
        st.write('''
                    **Controle de Mem√≥ria:**
                    Ao realizar opera√ß√µes em tensores, especialmente em modelos 
                    de aprendizado profundo com grandes conjuntos de dados, √© 
                    crucial otimizar o uso de mem√≥ria. O par√¢metro "out" permite 
                    controlar explicitamente onde o resultado da opera√ß√£o ser√° 
                    armazenado, evitando aloca√ß√µes de mem√≥ria desnecess√°rias e 
                    reduzindo a sobrecarga do sistema.

                    **Reutiliza√ß√£o de Mem√≥ria:**
                    Uma das vantagens do uso do par√¢metro "out" √© a capacidade de 
                    reutilizar a mem√≥ria alocada para tensores existentes. Em vez de 
                    alocar novos tensores para armazenar o resultado de uma opera√ß√£o, 
                    podemos especificar um tensor existente como destino para o resultado, 
                    economizando recursos de mem√≥ria e melhorando o desempenho geral.

                    **Efici√™ncia de C√≥digo:**
                    Usar o par√¢metro "out" tamb√©m pode resultar em c√≥digo mais limpo 
                    e leg√≠vel, pois evita a necessidade de atribuir o resultado da opera√ß√£o 
                    a uma vari√°vel separada. Isso pode simplificar o fluxo de trabalho de 
                    desenvolvimento e facilitar a manuten√ß√£o do c√≥digo ao longo do tempo.
                    ''')
        st.write('### Opera√ß√µes In-place')
        st.write(''' 
                    As opera√ß√µes in-place s√£o aquelas que modificam diretamente o 
                    tensor existente, sem criar um novo tensor para armazenar o 
                    resultado. Isso √© feito alterando os valores dos pr√≥prios 
                    elementos do tensor, em vez de alocar mem√≥ria para um novo 
                    tensor. Como resultado, as opera√ß√µes in-place s√£o mais eficientes 
                    em termos de uso de mem√≥ria e tempo de execu√ß√£o.''')
        st.write('''**Sintaxe e Exemplos:**
                    A sintaxe para realizar uma opera√ß√£o in-place em PyTorch √© adicionar
                    um sublinhado `_` ao final do nome da opera√ß√£o. Por exemplo, a opera√ß√£o
                    de adi√ß√£o in-place √© representada pelo m√©todo `add_()`.
                 ''')
        
        
            
        with st.expander('**Aplica√ß√£o de In-place operation**'):
             st.code('''
                        # In-place operation
                        # Mesmo que: x = x + y
                        x.add_(y)   
                    ''',language='python')
             st.write('**Mesmo que: x = x + y**')
             st.write(x.add_(y))
                        

          

if __name__ == "__main__":
    main()
