import streamlit as st
import torch
import pytorch_lightning as pl
from streamlit_option_menu import option_menu
import numpy as np
import pandas as pd


PAGE_TITLE = 'PyTorch Fundamentos ü§ñ'
PAGE_ICON = "ü§ñ"
st.set_page_config(page_title=PAGE_TITLE,page_icon=PAGE_ICON)

# Menu lateral
with st.sidebar:
    st.image('imagens/pytorch-logo.png',width=200)
    st.sidebar.title('PyTorch Fundamentos')
    selected = option_menu("",['0 - O que s√£o tensores?',
                               '1 - Criando Tensores',
                               '2 - Trabalhando com as dimens√µes dos Tensores',
                               '3 - Opera√ß√µes aritm√©ticas com Tensores',
                               '4 - Concatena√ß√£o, Expans√£o, Jun√ß√£o, Chunk, Squeeze'],
                               icons=['bi bi-droplet',
                                      'bi bi-droplet',
                                      'bi bi-droplet',
                                      'bi bi-droplet',
                                      'bi bi-droplet'],
                               default_index=0)

st.write("[Conhe√ßa o meu GitHub](https://github.com/AurelioGuilherme)")
st.write("[Documenta√ß√£o PyTorch](https://pytorch.org/docs/stable/index.html)")


def main():
    if selected == '0 - O que s√£o tensores?':
        st.write('# **O que s√£o tensores?**')
        st.write("""
                    O objeto tensor utilizado no framework PyTorch √© focado 
                    e projetado para processamento paralelizado. 
        
                    Ele representa uma estrutura de dados multidimensional 
                    que pode ser manipulada de forma eficiente em GPUs e CPUs. 
        
                    Essa capacidade de processamento paralelo √© essencial 
                    para lidar com grandes conjuntos de dados e realizar 
                    c√°lculos complexos de forma eficiente. 
        
                    Os tensores no PyTorch s√£o a base para a constru√ß√£o de 
                    modelos de aprendizado profundo e outras tarefas de 
                    computa√ß√£o cient√≠fica, fornecendo uma maneira flex√≠vel 
                    e eficaz de representar e manipular dados em v√°rias dimens√µes.
                 """)

        st.image('imagens/tensor.png')

        st.write("""
                    Os tensores s√£o amplamente utilizados em v√°rias √°reas, 
                    incluindo aprendizado de m√°quina, vis√£o computacional, 
                    processamento de linguagem natural e f√≠sica, entre outros. 
        
                    Eles fornecem uma maneira flex√≠vel e eficiente de 
                    representar e manipular dados em v√°rias dimens√µes. 
        
                    No aprendizado de m√°quina, os tensores s√£o usados para 
                    representar conjuntos de dados, par√¢metros de modelo, 
                    gradientes durante o treinamento e resultados de predi√ß√£o. 
        
                    Eles s√£o a base para a constru√ß√£o de modelos de aprendizado 
                    profundo, como redes neurais convolucionais e redes neurais recorrentes. 
        
                    Al√©m disso, em computa√ß√£o cient√≠fica, os tensores s√£o 
                    usados para representar tensores de tens√£o em mec√¢nica, 
                    campos vetoriais em f√≠sica e muito mais. 
                    Sua capacidade de processamento paralelo em hardware 
                    especializado os torna essenciais para lidar com grandes 
                    volumes de dados e realizar c√°lculos complexos de forma eficiente.
                """)
        st.image('imagens/img-1.png')

        st.write("""
                    Os tensores t√™m uma ampla gama de aplica√ß√µes pr√°ticas em diversas √°reas. 
                 
                    No processamento de imagens, os tensores s√£o usados para representar 
                    imagens digitais em tr√™s ou mais dimens√µes (largura, altura e canais de cor). 
        
                    Isso permite realizar opera√ß√µes como convolu√ß√µes e pooling em imagens 
                    para tarefas como classifica√ß√£o e detec√ß√£o de objetos. 
        
                    Em processamento de linguagem natural, os tensores s√£o usados para 
                    representar sequ√™ncias de palavras em texto e realizar opera√ß√µes 
                    como embeddings e aten√ß√£o em modelos de processamento de linguagem. 
        
                    Al√©m disso, em f√≠sica e engenharia, os tensores s√£o usados 
                    para representar grandezas f√≠sicas como tens√£o, deforma√ß√£o e 
                    fluxo de calor em sistemas complexos.
                """)
        st.image('imagens/April-28-deep-learning-applications-infograph.png')
        
    elif selected == '1 - Criando Tensores':
        st.write('# **Criando Tensores**')
        st.write("### Tensores PyTorch x Arrays NumPy:\n")

        st.write("""
                    Os tensores no PyTorch s√£o estruturas de dados multidimensionais 
                    que podem ter uma ou mais dimens√µes. As dimens√µes de um tensor 
                    representam a forma ou o tamanho de cada eixo do tensor. Por exemplo, 
                    um tensor bidimensional tem duas dimens√µes: uma dimens√£o 
                    para linhas e outra para colunas. 
                """)

        st.write('Voc√™ pode criar tensores a partir de listas ou matrizes numpy e vice-versa utilizando a fun√ß√£o `.Tensor()`')
        st.write('Esta fun√ß√£o cria um objeto do tipo tensor')
        lista_python = [[1,2,3], [4,5,6]]
        t1 = torch.Tensor(lista_python)  

        # Mostrar o c√≥digo
        with st.expander("**Cria um tensor 2x3 a partir de uma lista Python**"):
            st.code("""
                        import torch

                        # Cria um tensor 2x3 a partir de uma lista Python
                        lista_python = [[1,2,3], [4,5,6]]
                        t1 = torch.Tensor(lista_python)
                        print(t1)
                    """, language="python")
            st.write('**Valor do tensor t1 criado com uma lista python**')
            st.write(t1)

        array_numpy = np.array([[9,6,1], [5,3,2]])
        t2 = torch.Tensor(array_numpy)

        # Mostrar c√≥digo
        with st.expander('**Cria um tensor 2x3 a partir de array numpy**'):
            st.code('''
                        import torch
                        import numpy as np

                        # Cria um tensor 2x3 a partir de um array Numpy                    
                        array_numpy = np.array([[9,6,1], [5,3,2]])
                        t2 = torch.Tensor(array_numpy)
                        print(t2)                    
                    ''', language='python')
            st.write('**Valor do tensor t2 criado com uma array numpy**')
            st.write(t2)

        with st.expander('**Criando um tensor com range de valores com o m√©todo `.arange`**'):
            st.write('√â possivel criar um Tensor com um range de valores com o `.arange`')
            v = torch.arange(5)
            st.code('''
                       # Criando tensores com range de valores
                       v = torch.arange(5)
                       print(v)
                   ''',language='python')
            st.write('**Valor do Tensor v de 1 dimens√£o**')
            st.write(v)
            st.write('''O tensor criado √© em tensor em 1 dimens√£o, 
                        para mudar a dimens√£o podemos utilizar os metodos`.reshape()` e o `.view()` .''')
            st.code('''
                       #Criando tensor em 1 dimens√£o com arange
                       v = torch.arange(9)
                       print(v)
                   ''',language='python')
            v = torch.arange(9)
            st.write('**Valor tensor v em 1 dimens√£o**')
            st.write(v)
            st.code('''
                        # Alterando o tensor para 2 dimens√µes
                        v = v.view(3,3)
                        print(v)
                    ''',language='python')
            v = v.view(3,3)
            st.write('**Valor do tensor v em 2 dimens√µes**')
            st.write(v)
        with st.expander('**Criando um tensor Linear com `.linspace()`**'):
            st.write('''
                       O `torch.linspace()` √© particularmente √∫til
                       para gerar tensores lineares com valores igualmente espa√ßados ao 
                       longo de um intervalo especificado.

                        H√° tr√™s argumentos principais: o valor inicial do intervalo,
                        o valor final do intervalo e o n√∫mero de elementos desejados no tensor 
                     ''')
            v = torch.linspace(1, 10, steps=10)
            st.code(''' 
                       # Cria um tensor com 10 pontos lineares de (1, 10)
                       v = torch.linspace(1, 10, steps = 10)

                     ''',language='python')
            st.write('**Valor do tensor linear v**')
            st.write(v)

        with st.expander('**Criando um tensor em escala logar√≠timica**'):
            st.write('''
                        Ao usar `torch.logspace()`, fornecemos tr√™s argumentos principais: 
                        o expoente inicial, o expoente final e o n√∫mero de elementos desejados no 
                        tensor. O PyTorch ent√£o retorna um tensor com valores distribu√≠dos de forma 
                        logar√≠tmica entre 10^inicio e 10^fim, inclusive.
                   ''')
            v = torch.logspace(start = -1, end = 10, steps = 5 )
            st.code(''' 
                        # Criando tensor em escala logar√≠timica    
                        v = torch.logspace(start = -1, end = 10, steps = 5 )

                    ''',language='python')
            st.write('**Valor do tensor logar√≠timico**') 
            st.write(v)

        with st.expander('**Criando um tensor com valores absolutos**'):
            st.write('''
                       Para criar um tensor com valores absolutos em PyTorch,
                       voc√™ pode usar a fun√ß√£o `torch.abs()` para calcular os valores 
                       absolutos de um tensor existente ou pode criar um tensor com 
                       valores absolutos diretamente.''')
            f = torch.FloatTensor([-1, -2, 3])
            r = torch.abs(f)
            st.code('''
                        # Criando um tensor com valores neg√°tivos    
                        f = torch.FloatTensor([-1, -2, 3])
                    
                        # Convertendo o tensor para valores absolutos.
                        r = torch.abs(f)
                        print(r)
                    ''',language='python')
            st.write('**Valor do tensor r com valores absolutos**')
            st.write(r)
        

        st.write('### Tipos de Tensores no PyTorch')
        st.write('''
                    Ao criar tensores, podemos especificar suas dimens√µes e 
                    inicializ√°-los com diferentes valores. Por exemplo, 
                    podemos criar um tensor de zeros, onde todos os elementos 
                    do tensor t√™m o valor zero. Isso √© √∫til para inicializar 
                    tensores antes de realizar opera√ß√µes ou preench√™-los com 
                    dados reais posteriormente. Podemos criar um tensor de zeros 
                    usando a fun√ß√£o `torch.zeros(dimens√µes)`, onde "dimens√µes" √© 
                    uma lista ou tupla que especifica o tamanho de cada dimens√£o 
                    do tensor.

                    No entanto, √© importante ter cuidado ao trabalhar com tensores 
                    e gerenciar a mem√≥ria corretamente. √Äs vezes, ao criar ou manipular 
                    tensores, podemos gerar `"lixo de mem√≥ria"`, que s√£o √°reas de mem√≥ria 
                    alocadas para objetos que n√£o est√£o mais em uso, mas ainda n√£o foram liberadas. 
                    Isso pode levar a vazamentos de mem√≥ria e redu√ß√£o do desempenho do programa. 
                    Para evitar o lixo de mem√≥ria, √© importante liberar os recursos adequadamente 
                    ap√≥s o uso, usando m√©todos como "del" em tensores ou utilizando o mecanismo 
                    de coleta de lixo do Python.
                ''')
        a = torch.rand(2,2,3)

        # Mostrar c√≥digo
        with st.expander('Cria um tensor 2 x 2 x 3 com valores rand√¥micos'):
            st.code('''
                        import torch

                        # Cria um tensor 2 x 2 x 3 com valores rand√¥micos                   
                        a = torch.rand(2,2,3)
                        print(a)                    
                    ''', language='python')
            st.write(a)

        b = torch.zeros(2,2,3)

        # Mostrar c√≥digo
        with st.expander('Criando um tensor preenchido com zeros'):
            st.code('''
                        import torch

                        # Criando um tensor preenchido com zeros                  
                        b = torch.zeros(2,2,3)
                        print(b)                    
                    ''', language='python')
            st.write(b)

        c = torch.zeros_like(a)
        
        # Mostrar c√≥digo
        with st.expander('Criando um tensor semelhante a outro'):
            st.code('''
                        import torch
                                                                 
                        # Criando um tensor semelhante a outro              
                        c = torch.zeros_like(a)
                        print(c)                    
                    ''', language='python')
            st.write(c)

        d = torch.ones_like(a)

        # Mostrar c√≥digo
        with st.expander("**Criando um tensor de 1's semelhante (like) ao tensor de zeros (mesmas dimens√µes) `torch.ones_like()`**"):
            st.code('''
                        import torch

                        # Criando um tensor de 1's semelhante (like) ao tensor de zeros (mesmas dimens√µes)             
                        d = torch.ones_like(a)
                        print(d)                    
                    ''', language='python')
            st.write(d, unsafe_allow_html=True)
        
        with st.expander('**Tensor Diagonal `torch.diag()`**'):
             st.write('''Uma das opera√ß√µes comuns em √°lgebra linear √© a cria√ß√£o de uma matriz diagonal, 
                      na qual todos os elementos fora da diagonal principal s√£o zeros e os elementos 
                      na diagonal principal s√£o iguais. Em PyTorch, podemos facilmente criar um tensor 
                      diagonal de uns utilizando a fun√ß√£o `torch.diag()`.''')
             st.code('''
                        # Criando tensores de 1's  
                        v = torch.ones(3)
                        print(v)

                        # Transpondo para um Tensor de Size 3x3
                        r = torch.diag(v)
                        print(r)
                ''',language='python')
             v = torch.ones(3)
             st.write("**Tensor de 1's**")
             st.write(v)
             r = torch.diag(v)
             st.write('**Vetor Diagonal transposto**')
             st.write(r.numpy())
             



        st.write('### Criando tensores de diferentes tipos')
        st.write("""
        No PyTorch, existem diferentes tipos de tensores, cada um com suas pr√≥prias caracter√≠sticas e finalidades espec√≠ficas. Os principais tipos de tensores s√£o:

        1. Tensor Float: Este tipo de tensor √© utilizado para representar n√∫meros reais, sendo frequentemente empregado em tarefas de aprendizado de m√°quina, onde a precis√£o decimal √© importante. Podemos encontrar tensores float de 32 bits (torch.float32 ou torch.float) e 64 bits (torch.float64 ou torch.double), sendo que o primeiro √© mais comumente utilizado devido √† sua efici√™ncia computacional.

        2. Tensor Inteiro: Este tipo de tensor √© utilizado para representar n√∫meros inteiros. Assim como os tensores float, podemos encontrar tensores inteiros de diferentes tamanhos, como torch.int8, torch.int16, torch.int32 e torch.int64, dependendo da precis√£o necess√°ria para a aplica√ß√£o espec√≠fica.

        3. Tensor Booleano: Tensores booleanos s√£o utilizados para representar valores l√≥gicos, ou seja, verdadeiro ou falso. Eles s√£o frequentemente utilizados em opera√ß√µes de m√°scara e indexa√ß√£o.

        4. Tensor Byte: Este tipo de tensor √© semelhante ao tensor booleano, mas pode armazenar valores inteiros de 0 a 255, ocupando menos espa√ßo de mem√≥ria do que um tensor inteiro de 32 bits. √â comumente utilizado em opera√ß√µes de processamento de imagens.

        A exist√™ncia de m√∫ltiplos tipos de tensores no PyTorch se deve √† necessidade de flexibilidade e efici√™ncia em diferentes cen√°rios de aplica√ß√£o. Cada tipo de tensor oferece um compromisso entre precis√£o e efici√™ncia computacional, permitindo aos desenvolvedores escolher o tipo mais adequado para a sua aplica√ß√£o espec√≠fica. Isso permite otimizar o desempenho e o consumo de recursos do modelo, garantindo ao mesmo tempo a precis√£o necess√°ria para as tarefas em quest√£o.
                
        **Vejamos um exemplo de cria√ß√£o tensores:**""")

        a = np.array([[4,5,6], [7,8,9]])
        with st.expander('Criando numpy array'):
            st.code('''
                        import numpy as np

                        # Array numpy           
                        a = np.array([[4,5,6], [7,8,9]])
                        print(f'Tipo de dado Array Numpy: {a.dtype}')
                                       
                    ''', language='python')
            st.write(f'Tipo de dado Array Numpy: {a.dtype}')
            st.write(a)

        st.write('Por padr√£o o PyTorch utiliza o `FloatTensor` ao criar um objeto da classe tensor.')
        st.write('### Ponto de aten√ß√£o:')
        st.write('**CUIDADO:** Um objeto Tensor n√£o inicializado cont√©m dados de lixo de mem√≥ria!')
        
        b = torch.Tensor(a)
        with st.expander('Criando tensor utilizando o array'):
            st.code('''
                        import torch
                    
                        # Criando um Tensor.       
                        b = torch.Tensor(a)
                        print(f'Tipo de dado `Tensor`: {b.type()}')
                                       
                    ''', language='python')
            st.write(f"Tipo de dado Tensor: {b.type()}", unsafe_allow_html=True)
            st.write(b)
        
        c = torch.FloatTensor(a)
        with st.expander('Criando tensor um `FloatTensor` utilizando um array.'):
            st.code('''
                        import torch
                    
                        # Criando um FloatTensor        
                        c = torch.FloatTensor(a)
                        print(f'Tipo de dado `FloatTensor`: {c.type()}')
                                       
                    ''', language='python')
            st.write(f"Tipo de dado Tensor: {c.type()}", unsafe_allow_html=True)
            st.write(c)

        d = torch.LongTensor(a)
        with st.expander('Criando tensor um `LongTensor` utilizando o array.'):
            st.code('''
                        import torch
                    
                        # Criando um LongTensor        
                        d = torch.LongTensor(a)
                        print(f'Tipo de dado Tensor: {d.type()}')
                                       
                    ''', language='python')
            st.write(f"Tipo de dado Tensor: {d.type()}", unsafe_allow_html=True)
            st.write(d)            

        e = [True, False,True, True, True, False]
        f = torch.Tensor(e)
        with st.expander('Criando tensor a partir da lista de booleanos'):
            st.code('''
                        import torch

                        # Criando tensor a partir da lista de booleanos          
                        e = [True, False, True, True, False]
                        f = torch.Tensor(e)
                        print(f)
                        print(f.type())           
                    ''', language='python')
            st.write(f)
            st.write(f.type())
        
        g = torch.zeros(10, dtype = torch.bool)
        with st.expander('Criando tensor com valores booleanos'):
            st.code('''
                        import torch

                        # Criando tensor com valores booleanos         
                        g = torch.zeros(10, dtype = torch.bool)
                        print(g)
                        print(g.type())           
                    ''', language='python')
            st.write(g)
            st.write(g.type())
        
        st.write('### Alterando o tipo do tensor:')
        st.write("""
        √â comum a necessidade de converter tensores de um tipo para outro. Isso pode ser √∫til em v√°rias situa√ß√µes, como quando precisamos garantir a consist√™ncia dos tipos de dados em opera√ß√µes matem√°ticas ou quando queremos adaptar os tensores para diferentes opera√ß√µes ou modelos.

        Para converter um tensor para outro tipo, o PyTorch oferece diversos m√©todos. Por exemplo, podemos utilizar o m√©todo `.float()` para converter um tensor para ponto flutuante, ou `.long()` para converter para n√∫meros inteiros. Tamb√©m √© poss√≠vel utilizar m√©todos como `.double()`, `.half()`, `.bool()`, entre outros, dependendo das necessidades espec√≠ficas da aplica√ß√£o.

        Vejamos um exemplo de convers√£o de tipos de tensores:
                 """)
        a = np.array([[4,5,6], [7,8,9]])
        c = torch.FloatTensor(a)
        valor = c
        c = c.long()
        
        # Mostrar c√≥digo
        with st.expander('Mostrar c√≥digo'):
            st.code('''
                        import torch

                        # Alterando o tipo do tensor:
                        a = np.array([[4,5,6], [7,8,9]])
                        c = torch.FloatTensor(a)
                        print(c.type())
                        c = c.long()
                        print(c)
                        print(c.type())                                     
                    ''', language='python')
            st.write(valor.type())
            st.write(c)
            st.write(c.type())
            
    elif selected == '2 - Trabalhando com as dimens√µes dos Tensores':
        st.write('# **Trabalhando com as dimens√µes dos Tensores**')
        st.write('O slicing permite extrair partes espec√≠ficas de um tensor, permitindo o acesso aos elementos desejados.')
        st.write('### Size e Shape de Tensores')
        st.write('Visualizando as dimens√µes dos tensores com `shape` e `size()`')
        st.write('`shape`: √© um atributo')
        st.write('`size()`:  √© um m√©todo')
        
        # Cria um tensor com valores rand√¥micos
        torch.manual_seed(777)
        x = torch.randint(0, 10, size = (2, 3, 4))


        with st.expander('Mostrar c√≥digo'):
            st.code('''
                        import torch

                        # Cria um tensor com valores rand√¥micos
                        torch.manual_seed(777)
                        x = torch.randint(0, 10, size = (2, 3, 4))                   
                        print(x)

                        # Shape - Atributo do objeto tensor
                        x.shape

                        # Size - M√©todo do objeto tensor
                        x.size()                    

                        # N√∫mero total de elementos no Tensor                                   
                        torch.numel(x)

                        # Alterando o size do tensor (mas sem mudar o tensor original)
                        print(x.view(2, 2, 6))                                   
                    ''', language='python')
            st.write(x)
            st.write(x.shape)
            st.write(x.size())
            st.write(torch.numel(x))


        st.write('### View')
        st.write('Alterando o size do tensor (mas sem mudar o tensor original) com `view()`')
        
        # Mostrar c√≥digo
        with st.expander('Mostrar c√≥digo'):
            st.code('''
                       import torch
                                                                
                       # Cria um tensor com valores rand√¥micos
                       torch.manual_seed(777)
                       x = torch.randint(0, 10, size = (2, 3, 4))                   
                       
                       # Alterando o size do tensor (mas sem mudar o tensor original)
                       print(f"Altera de '{x.size()}' para '{x.view(2, 2, 6).size()}'\n")     
                       print(x.view(2, 2, 6))                                                     
                    ''', language='python')
            st.write(f"Altera de '{x.size()}' para '{x.view(2, 2, 6).size()}'\n")
            st.write(x.view(2, 2, 6))

        st.write('Tamb√©m podemos usar o m√©todo `view()` para criar um tensor')
        t = torch.arange(60).view(3, 4, 5)
        with st.expander('Mostrar c√≥digo:'):
            st.code('''
                        import torch

                        t = torch.arange(60).view(3, 4, 5)
                        print(t)
                        print(t.shape)
                        print(t.size())
                        print(torch.numel(t))
                    ''', language= 'python')
            st.write(t) 
            st.write(t.shape) 
            st.write(t.size()) 
            st.write(torch.numel(t))


        
        def create_tensor(dimensions):
            try:
                return torch.randint(low=0, high=11, size=dimensions)
            except ValueError:
                st.error('Digite dimens√µes v√°lidas para o tensor (n√∫meros inteiros separados por v√≠rgula).')

        st.write("### Slicing de Tensores")
        st.write('''
        Para realizar o slicing de um tensor, precisamos especificar os √≠ndices ou intervalos ao longo de cada dimens√£o do tensor. Podemos usar nota√ß√µes de intervalo para especificar o slicing de forma concisa e intuitiva.''')
        
        st.write('''
                    Sintaxe:

                    `tensor[tensor_position_start:tensor_position_end, tensor_dimension_start:tensor_dimension_end , tensor_value_start:tensor_value_end]`

                    Par√¢metros:

                    - tensor_position_start
                    - tensor_position_end
                    - tensor_dimension_start
                    - tensor_dimension_stop
                    - tensor_value_start
                    - tensor_value_stop
                ''')
        st.write('''
                 Vamos exemplificar com um exemplo interativo onde voc√™ pode fornecer as dimens√µes em um imput logo a baixo:
                 
                Neste exemplo √© criado um tensor com dimens√µes customizadas de acordo com o input e com seed definida para ter a possibilidade replica√ß√£o.
                
                Os valores dos tensores s√£o valore inteiros de 0 a 10.
                 ''')
        st.write('### Exemplo com input:')
        torch.manual_seed(222)
        dim_input = st.text_input("Digite as dimens√µes do tensor separadas por v√≠rgula (ex: 3,4,5):")

        if dim_input:
            dimensions = [int(dim) for dim in dim_input.split(',') if dim.isdigit()]
            dimensions = [max(0, min(dim, 9999999)) for dim in dimensions]
            x = create_tensor(dimensions)
            st.write(x)
            st.write('**Fazendo slice**')
            st.write(f'O tensor possui: {x.ndim} dimens√µes') 
            slice_input = st.text_input("Digite os valores para o slice do tensor separados por v√≠rgula (limitado √† quantidade de dimens√µes):")
            try:
                if slice_input:
                    slices = [int(s) for s in slice_input.split(',') if s.isdigit()]
                    result = x[tuple(slices)]  # Convertendo para uma tupla para indexa√ß√£o
                    st.write("Resultado do slicing:", result)
                    with st.expander('Mostrar c√≥digo: '):
                        st.code(f'''
                                # Cria um tensor com valores rand√¥micos
                                torch.manual_seed(222)
                                x = torch.randint(0, 10, size = {dimensions})
                                print(x)

                                # Slicing do tensor:
                                ### ps o print esta exibindo ':' ao inves de virgulas em casos especificos:
                                ### exemplo correto: print(x[0:1, 0:1, :3])
                                print(x[{str(slice_input).replace(',', ':')}])           
                                ''',language='python')
            except IndexError:
                st.error("√çndices de slice inv√°lidos.")

        st.write('''Fatiar um Tensor com slicing baseado em indexa√ß√£o √© √∫til, 
                     mas pode ser impratic√°vel com tensores de muitas dimens√µes.
                     Para fatiar um tensor 4D no PyTorch, voc√™ pode usar o m√©todo 
                     `tensor.narrow()`. Este m√©todo permite especificar as dimens√µes 
                     ao longo das quais deseja fatiar o tensor e os √≠ndices inicial e 
                     final de cada dimens√£o.''')
        
        st.write('**3 Dimens√µes**')
        x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
        with st.expander('Cria um tensor '):
                        st.code(f'''
                                x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                                print(x)
                                ''',language='python')
                        st.write(x)
        y = torch.narrow(x, 0, 0, 2)
        with st.expander('A partir da dimens√£o de √≠ndice 0, retorne as dimens√µes de √≠ndice 0 a 2 '):
                        st.code(f'''
                                y = torch.narrow(x, 0, 0, 2)
                                print(y)
                                ''',language='python')        
                        st.write(y)

        st.write('**4 Dimens√µes**')
        torch.manual_seed(333)
        tensor_4d = torch.randn(4,3,5,7)
        with st.expander('Cria um tensor de 4 dimens√µes'):
             st.code('''
                        torch.manual_seed(333)
                        tensor_4d = torch.randn(4,3,5,7)
                     
                        #Quantidade de dimens√µes
                        tensor_4d.dim()
                        print(tensor_4d)''',language='python')
             st.write(tensor_4d.dim())
             st.write(tensor_4d)
        sliced_tensor_4d = tensor_4d.narrow(2, 0, 2)
        with st.expander('A partir da dimens√£o de √≠ndice 2, retorne as dimens√µes entre √≠ndices 0 e 2. '):
             st.code('''
                        sliced_tensor_4d = tensor_4d.narrow(2, 0, 2)
                        sliced_tensor_4d.shape
                        print(sliced_tensor_4d)
                    ''',language='python')
             st.write(sliced_tensor_4d.shape)
             st.write(sliced_tensor_4d)
        
        st.write('**5 Dimens√µes**')
        torch.manual_seed(222)
        tensor_5d = torch.randn(4, 3, 5, 7, 3)
        with st.expander('Cria um tensor de 5 dimens√µes'):
            st.code(''' 
                        tensor_5d = torch.randn(4, 3, 5, 7, 3)
                        tensor_5d.dim()
                        print(tensor_5d)
                    ''', language='python')
            st.write(tensor_5d.dim())
            st.write(tensor_5d)
        
        sliced_tensor_5d = tensor_5d.narrow(2, 0, 2).narrow(3, 0, 1)
        with st.expander('A partir da dimens√£o de √≠ndice 2, retorne as dimens√µes entre √≠ndices 0 e 2. '):
             st.code('''
                        # Fa√ßa isso em todas as posi√ß√µes e coloca√ß√µes.
                        # Depois disso, a partir da dimens√£o de √≠ndice 3, retorne as dimens√µes os √≠ndices 0 e 1 (ou seja, somente √≠ndice 0)
                        sliced_tensor_5d = tensor_5d.narrow(2, 0, 2).narrow(3, 0, 1)

                        print(sliced_tensor_5d)
                    ''', language='python')
             st.write(sliced_tensor_5d)
    if selected == '3 - Opera√ß√µes aritm√©ticas com Tensores':
        st.write('# **Opera√ß√µes aritm√©ticas com Tensores**', unsafe_allow_html=True)
        st.write('''
                    Opera√ß√µes aritm√©ticas s√£o essenciais para a manipula√ß√£o e transforma√ß√£o de dados, 
                    desempenhando um papel cr√≠tico em todas as etapas do desenvolvimento de modelos.

                    **Soma e Subtra√ß√£o:**
                    As opera√ß√µes de soma e subtra√ß√£o s√£o simples e frequentemente usadas em opera√ß√µes de 
                    ajuste de par√¢metros, atualiza√ß√£o de gradientes e normaliza√ß√£o de dados. Por exemplo, 
                    ao treinar um modelo, essas opera√ß√µes podem ser usadas para calcular a diferen√ßa entre 
                    a sa√≠da prevista e o valor real (erro), que √© essencial para ajustar os pesos do modelo.

                ''')
        # Cria 2 tensores
        x = torch.rand(2, 3) 
        y = torch.rand(2, 3)

        # Opera√ß√£o de soma
        z1 = x + y
        with st.expander('**Opera√ß√£o de soma**'):
             st.code('''
                        # Cria 2 tensores
                        x = torch.rand(2, 3) 
                        y = torch.rand(2, 3)

                        # Opera√ß√£o de soma
                        z1 = x + y
                        print(z1)
                    ''',language='python')
             st.write('**Valor de x**')
             st.write(x)
             st.write('**Valor de y**')
             st.write(y)
             st.write('**Soma x + y**')
             st.write(z1)

        with st.expander('**Opera√ß√£o de soma com fun√ß√£o `.add`**'):
             z2 = torch.add(x, y)  
             st.code('''
                        # Cria 2 tensores
                        x = torch.rand(2, 3) 
                        y = torch.rand(2, 3)

                        # Opera√ß√£o soma com `.add`
                        z2 = torch.add(x, y)  
                        print(z2)
                    ''',language='python')
             st.write('**Valor de x**')
             st.write(x)
             st.write('**Valor de y**')
             st.write(y)
             st.write('**Soma x + y**')
             st.write(z2)

        with st.expander('**Somando valores a todos os elementos do tensor com `.add`**'):
            r = torch.add(x, 10)
            st.code('''
                        # Somando o valor 10 aos elementos do objeto Tensor.
                        r = torch.add(x, 10)
                        print(r)

                    ''', language='python')
            st.write('**Valor do tensor r ap√≥s soma**')
            st.write(r)
        
        with st.expander('**Subtra√ß√£o com o m√©todo `.sub()`**'):
            st.write('''
                       As formas anteriores para a soma como "x + y" tamb√©m funcionam para
                       o caso da subtra√ß√£o "x-y".
                       O m√©todo `.sub()` tamb√©m √© possivel utilizar de forma in-place e com par√¢metro out.
                    ''')
            # Criando um tensor
            x = torch.tensor([1, 2, 3])
            
            # Subtraindo um valor escalar
            y = torch.sub(x, 1)
            st.code('''
                        # Subtraindo valores
                        x = torch.Tensor([1,2,3])
                        y = torch.sub(x, 1)

                    ''',language='python')
            st.write('**Resultado da subtra√ß√£o**')
            st.write(y)
            
            

        st.write('### O Par√¢metro "out" em Opera√ß√µes de Tensores no PyTorch')  
        st.write('''
                    No PyTorch, o par√¢metro `out` em opera√ß√µes de tensores 
                    oferece uma maneira flex√≠vel de controlar onde o resultado 
                    da opera√ß√£o ser√° armazenado. Em muitas situa√ß√µes, podemos 
                    querer atribuir o resultado de uma opera√ß√£o a uma vari√°vel 
                    espec√≠fica ou a um local de mem√≥ria predefinido, e o 
                    par√¢metro "out" nos permite fazer isso de forma eficiente.
                 ''')
        v1 = torch.Tensor(2, 3)
        with st.expander('**Aplica√ß√£o do par√™metro `out`**'):        
            
            st.code('''
                        # Criando um tensor
                        v1 = torch.Tensor(2, 3)
                        print(v1)
                    ''',language='python')
            st.write('**Tensor v1**')
            st.write(v1)

            torch.add(x, y, out = v1)
            st.code('''
                        # Podemos atribuir o resultado da opera√ß√£o a uma vari√°vel. 
                        # Todos os m√©todos de opera√ß√£o possuem um par√¢metro out para armazenar o resultado.
                        torch.add(x, y, out = v1)
                    ''',language='python')
            st.write('**Tensor v1 com soma utilizando parametro `out`**')
            st.write(v1)

        st.write('### Aplica√ß√µes do par√¢metro Out') 
        st.write('''
                    **Controle de Mem√≥ria:**
                    Ao realizar opera√ß√µes em tensores, especialmente em modelos 
                    de aprendizado profundo com grandes conjuntos de dados, √© 
                    crucial otimizar o uso de mem√≥ria. O par√¢metro "out" permite 
                    controlar explicitamente onde o resultado da opera√ß√£o ser√° 
                    armazenado, evitando aloca√ß√µes de mem√≥ria desnecess√°rias e 
                    reduzindo a sobrecarga do sistema.

                    **Reutiliza√ß√£o de Mem√≥ria:**
                    Uma das vantagens do uso do par√¢metro "out" √© a capacidade de 
                    reutilizar a mem√≥ria alocada para tensores existentes. Em vez de 
                    alocar novos tensores para armazenar o resultado de uma opera√ß√£o, 
                    podemos especificar um tensor existente como destino para o resultado, 
                    economizando recursos de mem√≥ria e melhorando o desempenho geral.

                    **Efici√™ncia de C√≥digo:**
                    Usar o par√¢metro "out" tamb√©m pode resultar em c√≥digo mais limpo 
                    e leg√≠vel, pois evita a necessidade de atribuir o resultado da opera√ß√£o 
                    a uma vari√°vel separada. Isso pode simplificar o fluxo de trabalho de 
                    desenvolvimento e facilitar a manuten√ß√£o do c√≥digo ao longo do tempo.
                    ''')
        
        st.write('### Opera√ß√µes In-place')
        st.write(''' 
                    As opera√ß√µes in-place s√£o aquelas que modificam diretamente o 
                    tensor existente, sem criar um novo tensor para armazenar o 
                    resultado. Isso √© feito alterando os valores dos pr√≥prios 
                    elementos do tensor, em vez de alocar mem√≥ria para um novo 
                    tensor. Como resultado, as opera√ß√µes in-place s√£o mais eficientes 
                    em termos de uso de mem√≥ria e tempo de execu√ß√£o.''')
        st.write('''**Sintaxe e Exemplos:**
                    A sintaxe para realizar uma opera√ß√£o in-place em PyTorch √© adicionar
                    um sublinhado `_` ao final do nome da opera√ß√£o. Por exemplo, a opera√ß√£o
                    de adi√ß√£o in-place √© representada pelo m√©todo `add_()`.
                 ''')
        
        
            
        with st.expander('**Aplica√ß√£o de In-place operation**'):
             st.code('''
                        # In-place operation
                        # Mesmo que: x = x + y
                        x.add_(y)   
                    ''',language='python')
             st.write('**Mesmo que: x = x + y**')
             st.write(x.add_(y))

        st.write('### Somando valores pela indexa√ß√£o')
        st.write('Tamb√©m √© possivel efetuar oper√ß√µes pela indexa√ß√£o semelhante ao numpy') 
        x = torch.rand(2, 3)                     
        x[:, 0] = 0
        st.code('''
                    x[:, 1]                          
                    x[:, 0] = 0
                    print(x)
                ''',language='python')
        st.write(x)

        st.write('### Mais opera√ß√µes - Estat√≠stica')
        with st.expander('**Soma cumulativa `torch.cumsum()`**'):
            st.write('''
                        O m√©todo `.cumsum()` √© a fun√ß√£o que calcula a soma cumulativa ao longo de um eixo 
                        espec√≠fico do tensor, adicionando os elementos do tensor sequencialmente. 
                        Isso √© √∫til em uma variedade de cen√°rios, incluindo processamento de sinais, 
                        an√°lise de s√©ries temporais e em algoritmos de otimiza√ß√£o.
                     
                        Ao usar o m√©todo `cumsum()` em um tensor, podemos controlar o eixo ao longo do 
                        qual desejamos calcular a soma cumulativa. Por padr√£o, a soma cumulativa √© 
                        realizada ao longo do primeiro eixo do tensor, mas podemos especificar o 
                        eixo desejado como um par√¢metro.
                    ''')
            x = torch.Tensor([[1,2,3],
                              [4,5,6],
                              [7,8,9]])
            st.code(''' 
                        # Criando um tensor de 2 dimens√µes
                        x = torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])
                        print(x)
                    ''',language='python')
            st.write('**Valor do tensor x**')
            st.write(x)
            
            r = torch.cumsum(x, dim=0)
            st.code(''' 
                        # Soma acumulada por coluna
                        r = torch.cumsum(x, dim = 0)
                        print(r)
                    ''', language='python')
            st.write('**Soma acumulada por coluna**')
            st.write(r)

            r = torch.cumsum(x, dim=1)
            st.code(''' 
                        # Soma acumulada por linha
                        r = torch.cumsum(x, dim = 1)
                        print(r)
                    ''', language='python')
            st.write('**Soma acumulada por linha**')
            st.write(r)

        with st.expander('**M√©dia `torch.mean()`**'):
             st.write('''
                        Ao utilizar o m√©todo `torch.mean()` em um tensor, o PyTorch calcula a 
                        m√©dia de todos os elementos do tensor ou ao longo de um eixo especificado. 
                        Se nenhum eixo for especificado, a m√©dia de todos os elementos do 
                        tensor √© calculada. No entanto, se um eixo for fornecido, o c√°lculo da m√©dia 
                        ser√° realizado ao longo desse eixo.
                     ''')
             r = torch.mean(x)
             st.code('''
                        import torch
                        # Cria 1 tensor de 2 dimens√µes
                        x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                     
                        # M√©dia dos valores do Tensor
                        r = torch.mean(x)       
                        print(r)

                    ''',language='python')
             st.write('**M√©dia dos valores do Tensor**')
             st.write(r)

             r = torch.mean(x, 0)
             st.code('''
                        # M√©dia por coluna
                        r = torch.mean(x, 0) 
                        print(r)
                     ''',language='python')
             st.write('**M√©dia dos valores do Tensor por coluna**')
             st.write(r)

             r = torch.mean(x, 1)
             st.code('''
                        # M√©dia por linha
                        r = torch.mean(x, 1) 
                        print(r)
                     ''',language='python')
             st.write('**M√©dia dos valores do Tensor por linha**')
             st.write(r)
        
        with st.expander('**Desvio padr√£o `torch.std()`**'):
             st.write('''
                        O desvio padr√£o √© uma medida estat√≠stica que indica a dispers√£o 
                        dos valores em torno da m√©dia de um conjunto de dados. No PyTorch, 
                        o c√°lculo do desvio padr√£o de tensores √© facilitado pelo m√©todo `.std()`,
                         que retorna o desvio padr√£o dos elementos do tensor.

                        Ao utilizar o m√©todo `.std()` em um tensor em PyTorch, podemos calcular 
                        rapidamente o desvio padr√£o de todos os elementos do tensor ou ao longo 
                        de um eixo espec√≠fico em tensores multidimensionais. Se nenhum eixo for 
                        especificado, o desvio padr√£o ser√° calculado para todos os elementos do tensor.
                     ''')
             st.code('''
                        import torch
                        # Cria 1 tensor de 2 dimens√µes
                        x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                       
                        # Desvio padr√£o do tensor
                        print(x.std())
                     
                        # Desvio padr√£o por linha
                        print(x.std(dim =1))
                    ''',language='python')
             st.write('**Desvio padr√£o do tensor**')
             st.write(x.std())
             st.write('**Desvio padr√£o do tensor por linha**')
             st.write(x.std(dim = 1))

        with st.expander('**Soma dos elementos do tensor `torch.sum()`**'):
            st.write('''
                        Ao usar o m√©todo .sum() em um tensor, podemos controlar o eixo ao 
                        longo do qual desejamos calcular a soma. Por padr√£o, a soma √© realizada 
                        em todos os elementos do tensor, mas podemos especificar o eixo 
                        desejado como um par√¢metro.''')
            st.code('''
                        import torch
                        # Cria 1 tensor de 2 dimens√µes
                        x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
                    
                        # Soma total
                        r = torch.sum(x)         
                        print(r)
                    
                        # Soma por coluna
                        r = torch.sum(x, 0)         
                        print(r)
                    
                        # Soma por linha
                        r = torch.sum(x, 1)         
                        print(r)
                    ''',language='python')
            st.write('**Soma total**')
            st.write(torch.sum(x))
            st.write('**Soma por coluna**')
            st.write(torch.sum(x,0))
            st.write('**Soma por linha**')
            st.write(torch.sum(x,1))

        st.write('## **Multiplica√ß√£o de Matrizes**')
        st.write('''
                    Vamos explorar tr√™s tipos fundamentais de multiplica√ß√£o de 
                    matrizes em PyTorch: multiplica√ß√£o elemento a elemento (element-wise), 
                    produto escalar (dot product) e produto vetorial (cross product).
               ''')
        st.write('### Multiplica√ß√£o Element-wise em PyTorch:')
        st.write('''
                 A multiplica√ß√£o elemento a elemento em PyTorch √© realizada diretamente 
                 usando o operador de multiplica√ß√£o (*) ou pelo m√©todo `torch.mul()`. Esta opera√ß√£o √© aplicada entre 
                 dois tensores de mesma forma e resulta em um novo tensor com os elementos 
                 multiplicados elemento a elemento. A multiplica√ß√£o elemento a elemento √© √∫til 
                 em muitas aplica√ß√µes, incluindo opera√ß√µes de ativa√ß√£o em redes neurais e opera√ß√µes 
                 ponto a ponto em processamento de sinais.''')
        st.image('imagens/elementwise.jpg')
        
        with st.expander('**Multiplica√ß√£o Element-wise**'):
             x = torch.Tensor([[1,2],[3,4]])
             y = torch.Tensor([[5,2],[4,5]])
             r = torch.mul(x, y)
             st.code('''
                        # Criando os tensores
                        x = torch.Tensor([[1,2],[3,4]])
                        y = torch.Tensor([[5,2],[4,5]])
                     
                        # Multiplicando tensor x * y    
                        r = torch.mul(x, y) 
                        print(r)
                    ''',language='python')
             st.write('**Resultado da multiplica√ß√£o tensor x*y (Element-Wise)**')
             st.write(r)
        st.write('### Multiplica√ß√£o Dot Product')
        st.write('''
                    O produto escalar ou multiplica√ß√£o Dot Product em PyTorch √© realizado usando a fun√ß√£o `torch.dot()`. 
                    Esta fun√ß√£o calcula o produto escalar entre dois tensores unidimensionais 
                    (vetores), multiplicando seus elementos correspondentes e somando-os. 
                    O produto escalar √© comumente usado em c√°lculos de similaridade, proje√ß√µes 
                    e otimiza√ß√£o de modelos de aprendizado de m√°quina.
                ''')
        st.image('imagens/dotproduct.png')
        with st.expander('**Multiplica√ß√£o Dot Product**'):
             t1 = torch.Tensor([4,2])
             t2 = torch.Tensor([3,1])
             r = torch.dot(t1, t2)
             st.code('''
                        # Criando dois tensores
                        t1 = torch.Tensor([4,2])
                        t2 = torch.Tensor([3,1])

                        # Multiplicando os tensores.
                        r = torch.dot(t1, t2)
                        print(r)   

                        ''', language='python')
             st.write('**Produto escalar t1 * t2 (Dot Product)**')
             st.write(r)

        st.write('### Multiplica√ß√£o Cross Product')
        st.write('''A multiplica√ß√£o Cross product √© um produto de uma  multiplica√ß√£o cruzada
                    onde podemos multiplicar matrizes e vetores com dimens√µes diferentes.''')

        with st.expander('**Multiplica√ß√£o de Matriz por Vetor `torch.mv`**'):
             st.write('Nesta opera√ß√£o, multiplicamos uma matriz por um vetor para obter um novo vetor.')
             mat = torch.randn(2, 4)
             vec = torch.randn(4)
             st.code('''
                        # Criando Matriz e Tensor
                        mat = torch.randn(2, 4)
                        vec = torch.randn(4)
                        print(mat)
                        print(vec)
                     
                        #Multiplicando a matriz e vetor
                        r = torch.mv(mat, vec)
                        print(r)
                    ''',language='python')

             st.write('**Matriz**')
             st.write(mat)
             st.write('**Vetor**')
             st.write(vec)

             st.write('**Multiplica√ß√£o entre Matriz e Vetor**')
             r = torch.mv(mat, vec)
             st.write(r)
             st.write('Tamb√©m √© possivel efetuar uma soma ao multiplicarmos uma Matriz x Vetor `torch.addmv()`')
             st.code('''
                        # Multiplica√ß√£o entre Matriz e Vetor e ao resultado somamos outro vetor.
                        V = torch.randn(2)
                        mat = torch.randn(2, 3)
                        vec = torch.randn(3)
                        
                        # Vetor + (Matriz X Vetor)
                        r = torch.addmv(V, mat, vec)
                        print(r)
                        
                    ''',language='python')
             V = torch.randn(2)
             mat = torch.randn(2, 3)
             vec = torch.randn(3)
             r = torch.addmv(V, mat, vec)
             st.write('**Vetor + (Matriz X Vetor)**')
             st.write(r)

        with st.expander('**Multiplica√ß√£o entre matrizes - Cross Product `torch.cross`**'):
             st.write('''Essa fun√ß√£o aceita dois tensores com a mesma 
                      forma e calcula o produto cruzado entre eles, produzindo um novo tensor''')
             st.code('''
                        # # Multiplica√ß√£o entre Matrizes com produto cruzado (cross product)
                        # Matriz X Matriz
                        
                        m1 = torch.rand(3, 5)
                        m2 = torch.rand(3, 5)
                        r = torch.cross(m1, m2)
                     
                        # Resultado Size 3x5
                        print(r)
                        print(r.size())

                    ''',language='python')
             m1 = torch.rand(3, 5)
             m2 = torch.rand(3, 5)
             r = torch.cross(m1, m2)
             st.write('**Tensor 1**')   
             st.write(m1)
             st.write('**Tensor 2**') 
             st.write(m2)
             st.write('**Resultado Multiplica√ß√£o Cross Product**')
             st.write(r)

    if selected == '4 - Concatena√ß√£o, Expans√£o, Jun√ß√£o, Chunk, Squeeze':
         st.write('# Manipula√ß√£o de Tensores.')
         st.write('Existem diversas formas de manipular e tensores:')
         with st.expander('**Expans√£o`torch.expand()`**'):
              st.write('''A expans√£o, tamb√©m conhecida como broadcasting, √© uma opera√ß√£o fundamental
                        em PyTorch que permite realizar opera√ß√µes entre tensores de diferentes formas, 
                       ajustando automaticamente as dimens√µes dos tensores menores para que sejam 
                       compat√≠veis com as dimens√µes dos tensores maiores. Essa opera√ß√£o √© especialmente 
                       √∫til quando precisamos realizar opera√ß√µes entre tensores de formas diferentes sem 
                       precisar criar c√≥pias adicionais dos dados.''')
              
              x = torch.tensor([[1],[2],[3]])
              st.code(''' 
                        # Criando um tensor - size 3x1
                        x = torch.tensor([[1],[2],[3]])
                        print(x)
                      ''',language='python')
              st.write('**Tensor - Size 3x1**')
              st.write(x.numpy())

              st.code('''
                      # Expandindo um tensor
                      x.expand(3, 4)
                      ''',language='python')
              st.write(x.expand(3, 4).numpy())

         with st.expander('**Concatena√ß√£o `torch.cat()`**'):
              st.write(''' A concatena√ß√£o √© uma opera√ß√£o que permite combinar tensores
                        ao longo de um eixo espec√≠fico. Isso √© √∫til para combinar 
                       dados de diferentes fontes ou para aumentar o tamanho de um tensor''')
              st.code('''
                        # Criando tensor - Size 5x3
                        x = torch.randn(5, 3).type(torch.FloatTensor)
                        print(x)
                        ''',language='python')
              x = torch.randn(5, 3).type(torch.FloatTensor)
              st.write('**Tensor x - Size 5x3**')
              st.write(x.numpy())
              
              st.code('''
                        # Concatena√ß√£o por linha
                        x_row = torch.cat((x, x, x), 0)
                        print(x_row)  
                      ''',language='python')
              st.write('**Concatena√ß√£o por linha**')  
              st.write(torch.cat((x, x, x), 0).numpy())
              
              st.code('''
                        # Concatena√ß√£o por coluna
                        x_col = torch.cat((x, x, x), 1)
                        print(x_col)  
                      ''',language='python')
              st.write('**Concatena√ß√£o por coluna**')  
              st.write(torch.cat((x, x, x), 1).numpy())

         with st.expander('**Jun√ß√£o (Stacking) `torch.stack()`**'):
              st.write('''A jun√ß√£o √© uma opera√ß√£o que permite empilhar tensores ao longo 
                       de um novo eixo. Isso √© √∫til para combinar m√∫ltiplos tensores em 
                       um √∫nico tensor multidimensional. ''')
                                  
              
             

            
        
if __name__ == "__main__":
    main()
